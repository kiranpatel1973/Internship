{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f86744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    1.                            \"Baby Shark Dance\"[3]   \n",
      "1    2.                                   \"Despacito\"[6]   \n",
      "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
      "3    4.                               \"Shape of You\"[13]   \n",
      "4    5.                              \"See You Again\"[15]   \n",
      "5    6.                                  \"Bath Song\"[20]   \n",
      "6    7.                \"Phonics Song with Two Words\"[21]   \n",
      "7    8.                                \"Uptown Funk\"[22]   \n",
      "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
      "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
      "10  11.                              \"Gangnam Style\"[25]   \n",
      "11  12.                          \"Wheels on the Bus\"[30]   \n",
      "12  13.                             \"Dame Tu Cosita\"[31]   \n",
      "13  14.                                      \"Sugar\"[32]   \n",
      "14  15.                                       \"Roar\"[33]   \n",
      "15  16.                             \"Counting Stars\"[34]   \n",
      "16  17.                                      \"Sorry\"[35]   \n",
      "17  18.                          \"Thinking Out Loud\"[36]   \n",
      "18  19.                                     \"Axel F\"[37]   \n",
      "19  20.                             \"Girls Like You\"[38]   \n",
      "20  21.                                      \"Faded\"[39]   \n",
      "21  22.                                 \"Dark Horse\"[40]   \n",
      "22  23.                        \"Baa Baa Black Sheep\"[41]   \n",
      "23  24.                                 \"Let Her Go\"[42]   \n",
      "24  25.                                   \"Bailando\"[43]   \n",
      "25  26.                                    \"Lean On\"[44]   \n",
      "26  27.                                    \"Perfect\"[45]   \n",
      "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
      "28  29.                               \"Shake It Off\"[47]   \n",
      "29  30.                                   \"Mi Gente\"[48]   \n",
      "\n",
      "                                    Artist Name        Upload Date  Views  \n",
      "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.00  \n",
      "1                                    Luis Fonsi   January 12, 2017   7.92  \n",
      "2                                   LooLoo Kids    October 8, 2016   6.40  \n",
      "3                                    Ed Sheeran   January 30, 2017   5.77  \n",
      "4                                   Wiz Khalifa      April 6, 2015   5.58  \n",
      "5                    Cocomelon – Nursery Rhymes        May 2, 2018   5.53  \n",
      "6                                     ChuChu TV      March 6, 2014   4.74  \n",
      "7                                   Mark Ronson  November 19, 2014   4.64  \n",
      "8                                   Miroshka TV  February 27, 2018   4.59  \n",
      "9                                    Get Movies   January 31, 2012   4.50  \n",
      "10                                          Psy      July 15, 2012   4.49  \n",
      "11                   Cocomelon – Nursery Rhymes       May 24, 2018   4.23  \n",
      "12                                    El Chombo      April 5, 2018   3.99  \n",
      "13                                     Maroon 5   January 14, 2015   3.73  \n",
      "14                                   Katy Perry  September 5, 2013   3.62  \n",
      "15                                  OneRepublic       May 31, 2013   3.61  \n",
      "16                                Justin Bieber   October 22, 2015   3.57  \n",
      "17                                   Ed Sheeran    October 7, 2014   3.47  \n",
      "18                                   Crazy Frog      June 16, 2009   3.44  \n",
      "19                                     Maroon 5       May 31, 2018   3.31  \n",
      "20                                  Alan Walker   December 3, 2015   3.31  \n",
      "21                                   Katy Perry  February 20, 2014   3.31  \n",
      "22                   Cocomelon – Nursery Rhymes      June 25, 2018   3.30  \n",
      "23                                    Passenger      July 25, 2012   3.26  \n",
      "24                             Enrique Iglesias     April 11, 2014   3.24  \n",
      "25                                  Major Lazer     March 22, 2015   3.23  \n",
      "26                                   Ed Sheeran   November 9, 2017   3.21  \n",
      "27                                      Shakira       June 4, 2010   3.20  \n",
      "28                                 Taylor Swift    August 18, 2014   3.19  \n",
      "29                                     J Balvin      June 29, 2017   3.11  \n",
      "  Match Title                                Series Name  \\\n",
      "0   3rd ODI    INDIA TOUR OF WEST INDIES ODI SERIES 2022   \n",
      "1  1st T20I       COMMONWEALTH GAMES WOMENS CRICKET 2022   \n",
      "2  1st T20I    INDIA TOUR OF WEST INDIES T20 SERIES 2022   \n",
      "3  2nd T20I       COMMONWEALTH GAMES WOMENS CRICKET 2022   \n",
      "4  2nd T20I    INDIA TOUR OF WEST INDIES T20 SERIES 2022   \n",
      "5  3rd T20I    INDIA TOUR OF WEST INDIES T20 SERIES 2022   \n",
      "6  3rd T20I       COMMONWEALTH GAMES WOMENS CRICKET 2022   \n",
      "7  4th T20I    INDIA TOUR OF WEST INDIES T20 SERIES 2022   \n",
      "\n",
      "                                               Place         Date  \\\n",
      "0                        Queen's Park Oval, Trinidad  27 JUL 2022   \n",
      "1                              Edgbaston, Birmingham  29 JUL 2022   \n",
      "2                       Brian Lara Stadium, Trinidad  29 JUL 2022   \n",
      "3                              Edgbaston, Birmingham  31 JUL 2022   \n",
      "4                              Warner Park, St Kitts   1 AUG 2022   \n",
      "5                              Warner Park, St Kitts   2 AUG 2022   \n",
      "6                              Edgbaston, Birmingham   3 AUG 2022   \n",
      "7   Central Broward Regional Park Stadium Turf Gr...   6 AUG 2022   \n",
      "\n",
      "           Time  \n",
      "0   7:00 PM IST  \n",
      "1   4:30 PM IST  \n",
      "2   8:00 PM IST  \n",
      "3   4:30 PM IST  \n",
      "4   8:00 PM IST  \n",
      "5   8:00 PM IST  \n",
      "6  11:30 PM IST  \n",
      "7   8:00 PM IST  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ElementClickInterceptedException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KIRANK~1.PAT\\AppData\\Local\\Temp/ipykernel_23012/2317247224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mhrefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//a[@data-lasso-id='182688']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mElementClickInterceptedException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    772\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.134)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x008DD953+2414931]\n\tOrdinal0 [0x0086F5E1+1963489]\n\tOrdinal0 [0x0075C6B8+837304]\n\tOrdinal0 [0x0074EB34+781108]\n\tOrdinal0 [0x0074E06A+778346]\n\tOrdinal0 [0x0074D646+775750]\n\tOrdinal0 [0x0074C565+771429]\n\tOrdinal0 [0x0074CB68+772968]\n\tOrdinal0 [0x0074CAF8+772856]\n\tOrdinal0 [0x00752D5A+798042]\n\tOrdinal0 [0x0074DD3B+777531]\n\tOrdinal0 [0x0074E265+778853]\n\tOrdinal0 [0x0074E04F+778319]\n\tOrdinal0 [0x0074D646+775750]\n\tOrdinal0 [0x0074CEBC+773820]\n\tOrdinal0 [0x00762197+860567]\n\tOrdinal0 [0x007B4B55+1198933]\n\tOrdinal0 [0x007A42B6+1131190]\n\tOrdinal0 [0x0077E860+976992]\n\tOrdinal0 [0x0077F756+980822]\n\tGetHandleVerifier [0x00B4CC62+2510274]\n\tGetHandleVerifier [0x00B3F760+2455744]\n\tGetHandleVerifier [0x0096EABA+551962]\n\tGetHandleVerifier [0x0096D916+547446]\n\tOrdinal0 [0x00875F3B+1990459]\n\tOrdinal0 [0x0087A898+2009240]\n\tOrdinal0 [0x0087A985+2009477]\n\tOrdinal0 [0x00883AD1+2046673]\n\tBaseThreadInitThunk [0x7759FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x778A7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x778A7A6E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KIRANK~1.PAT\\AppData\\Local\\Temp/ipykernel_23012/2317247224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mhrefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//a[@data-lasso-id='182688']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[1;32mexcept\u001b[0m \u001b[0mElementClickInterceptedException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'here'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ElementClickInterceptedException' is not defined"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import WebDriverException,ElementNotInteractableException,NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Youtube From Wiki\n",
    "driver = webdriver.Chrome('chromedriver.exe')                                    ## connect to web driver\n",
    "driver.maximize_window()                                                         ## maximize the browser window\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')   ## open web page\n",
    "time.sleep(5)                                                                    ## Wait for 2 sec for the page to get open\n",
    "\n",
    "## Scrape Data\n",
    "rank =[]\n",
    "name =[]\n",
    "artist =[]\n",
    "upd_dat =[]\n",
    "views =[]\n",
    "\n",
    "rank_list = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "for a in rank_list:\n",
    "    rank.append(a.text)\n",
    "\n",
    "name_list = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "for b in name_list:\n",
    "    name.append(b.text)\n",
    "    \n",
    "artist_list = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "for c in artist_list:\n",
    "    artist.append(c.text)\n",
    "    \n",
    "upload_list = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "for d in upload_list:\n",
    "    upd_dat.append(d.text)\n",
    "\n",
    "view_list = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "for e in view_list:\n",
    "    views.append(e.text)\n",
    "\n",
    "if len(rank)==len(name)==len(artist)==len(upd_dat)==len(views):\n",
    "    youtube_videos_df = pd.DataFrame({'Rank':rank,'Name':name,'Artist Name':artist,'Upload Date':upd_dat,'Views':views})\n",
    "    print(youtube_videos_df)\n",
    "driver.close()\n",
    "\n",
    "# Youtube From Wiki\n",
    "\n",
    "# bcci.tv\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')                                    ## connect to web driver\n",
    "driver.maximize_window()                                                         ## maximize the browser window\n",
    "driver.get('https://www.bcci.tv/')                                               ## open web page\n",
    "time.sleep(5)                                                                    ## Wait for 2 sec for the page to get open\n",
    "\n",
    "inte_sele = driver.find_element_by_xpath(\"//div[@class='collapse navbar-collapse']/ul/li[2]\").click()\n",
    "time.sleep(5)    \n",
    "\n",
    "## Scrape Data\n",
    "match_title =[]\n",
    "series =[]\n",
    "place =[]\n",
    "date =[]\n",
    "tim=[]\n",
    "\n",
    "mt_list = driver.find_elements_by_xpath(\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "for x in mt_list:\n",
    "    match_title.append(x.text.replace(\"-\",\" \"))\n",
    "\n",
    "se_list = driver.find_elements_by_xpath(\"//span[@class='ng-binding']\")\n",
    "for y in se_list:\n",
    "    series.append(y.text)\n",
    "    \n",
    "pl_list = driver.find_elements_by_xpath(\"//div[@class='fix-place ng-binding ng-scope']\")\n",
    "for z in pl_list:\n",
    "    place.append(z.text.split(\"-\").pop(1))\n",
    "       \n",
    "d_list = driver.find_elements_by_xpath(\"//h5[@class='ng-binding']\")\n",
    "for a in d_list:\n",
    "    date.append(a.text)\n",
    "\n",
    "t_list = driver.find_elements_by_xpath(\"//h5[@class='text-right ng-binding']\")\n",
    "for b in t_list:\n",
    "    tim.append(b.text)\n",
    "\n",
    "bcci_df = pd.DataFrame({'Match Title':match_title,'Series Name':series,'Place':place,'Date':date,'Time':tim})\n",
    "print(bcci_df)\n",
    "    \n",
    "driver.close()\n",
    "# bcci.tv\n",
    "\n",
    "#guru99.com\n",
    "driver = webdriver.Chrome('chromedriver.exe')                                    ## connect to web driver\n",
    "driver.implicitly_wait(100)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.maximize_window()                                                         ## maximize the browser window\n",
    "driver.get('https://www.guru99.com/')                                            ## open web page\n",
    "try:\n",
    "    sele_from_menu = driver.find_element_by_xpath(\"//ul[@class='menu1']/li[3]\").click()\n",
    "except WebDriverException:\n",
    "    print('first click')\n",
    "try:\n",
    "    hrefs = driver.find_element_by_xpath(\"//a[@data-lasso-id='182688']\").click()\n",
    "except ElementClickInterceptedException:\n",
    "    print('here')\n",
    "\n",
    "try:\n",
    "    exc_name =[]\n",
    "    list_of_name = driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "    for n in list_of_name:\n",
    "        exc_name.append(n.text)\n",
    "except WebDriverException:\n",
    "    print('no exceptions')\n",
    "    \n",
    "try:\n",
    "    exc_desc =[]\n",
    "    list_of_desc = driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "    for m in list_of_desc:\n",
    "        exc_desc.append(m.text)\n",
    "except WebDriverException:\n",
    "    print('no description')\n",
    "\n",
    "if len(exc_name) == len(exc_desc):\n",
    "    sele_exp_df = pd.DataFrame({'Name':exc_name,'Description':exc_desc})\n",
    "\n",
    "print(sele_exp_df)\n",
    "driver.close()\n",
    "#guru99.com\n",
    "\n",
    "# Statistic \n",
    "driver = webdriver.Chrome('chromedriver.exe')                                    ## connect to web driver\n",
    "driver.implicitly_wait(10)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.maximize_window()                                                         ## maximize the browser window\n",
    "driver.get('http://statisticstimes.com/')                 \n",
    "coo_msg = driver.find_element_by_xpath(\"//div[@class='cc-compliance']/a\").click()\n",
    "eco = driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[3]\")\n",
    "try:\n",
    "    eco.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(eco.get_attribute('href'))\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "ind_sta_gdp = driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']//li[1]/a\")\n",
    "try:\n",
    "    ind_sta_gdp.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(ind_sta_gdp.get_attribute('href'))\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "#scraping data\n",
    "rank=[]\n",
    "try:\n",
    "    rank_list = driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for x in rank_list:\n",
    "        rank.append(x.text)\n",
    "except NoSuchElementException:                \n",
    "    rank.append('No details available')\n",
    "driver.implicitly_wait(10)  \n",
    "\n",
    "state=[]\n",
    "try:\n",
    "    state_list = driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for y in state_list:\n",
    "        state.append(y.text)\n",
    "except NoSuchElementException:                \n",
    "    state.append('No details available')\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "gsdp_1819 =[]\n",
    "try:\n",
    "    gsdp_1819_list = driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for z in gsdp_1819_list:\n",
    "        gsdp_1819.append(z.text)\n",
    "except NoSuchElementException:                \n",
    "    gsdp_1819.append('No details available')\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "share =[]\n",
    "try:\n",
    "    share_list = driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for a in share_list:\n",
    "        share.append(a.text)\n",
    "except NoSuchElementException:                \n",
    "    share.append('No details available')\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "gdp_bil = []\n",
    "try:\n",
    "    gdpbil_list = driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "    for b in gdpbil_list:\n",
    "        gdp_bil.append(b.text)\n",
    "except NoSuchElementException:                \n",
    "    gdp_bil.append('No details available')\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "#creatng dataframe\n",
    "df=pd.DataFrame({'Rank':rank,\n",
    "                'State':State,\n",
    "                'GSDP(18-19)':gsdp_1819,\n",
    "                'Share(18-19)':share,\n",
    "                'GDP(Billion_$)':gdp_bil})\n",
    "df\n",
    "\n",
    "## Statistic \n",
    "\n",
    "## GitHub\n",
    "driver = webdriver.Chrome('chromedriver.exe')                                    ## connect to web driver\n",
    "driver.maximize_window()                                                         ## maximize the browser window\n",
    "driver.get('https://github.com/')                                                ## open web page\n",
    "time.sleep(5)                                                                    ## Wait for 5 sec for the page to get open\n",
    "\n",
    "explore=driver.find_element_by_xpath(\"//ul[@class='d-lg-flex list-style-none']/li[4]\")\n",
    "try:\n",
    "    explore.click()\n",
    "except NoSuchElementException:\n",
    "    driver.get(explore.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n",
    "trend = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a\")\n",
    "try:\n",
    "    trend.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trend.get_attribute('href'))\n",
    "time.sleep(2)    \n",
    "\n",
    "repo_title=[]\n",
    "repo_desc=[]\n",
    "contri_cnt=[]\n",
    "lang_used=[]\n",
    "repo_url=[]\n",
    "\n",
    "repo_list = driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\")\n",
    "for x in repo_list:\n",
    "    repo_title.append(x.text)\n",
    "    \n",
    "repo_url_list = driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for y in repo_url_list:\n",
    "    repo_url.append(y.get_attribute('href'))\n",
    "\n",
    "for i in repo_url:\n",
    "    driver.get(i)\n",
    "    l=[]\n",
    "    time.sleep(5)\n",
    "     #scraping repositories discription\n",
    "    try:          \n",
    "        repo_desc.append(driver.find_element_by_xpath(\"//p[@class='f4 mt-3']\").text)\n",
    "    except:\n",
    "        repo_desc.append('-')\n",
    "        \n",
    "    try:\n",
    "        count=driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        contri_cnt.append(count.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        contri_cnt.append('No details available')\n",
    "        time.sleep(5) \n",
    "    \n",
    "    languages=driver.find_elements_by_xpath(\"//li[@class='d-inline']//a//span[1]\")\n",
    "    if languages:    \n",
    "        for i in languages:\n",
    "            l.append(i.text)\n",
    "    else:\n",
    "        l.append('No languages used')\n",
    "    lang_used.append(l) \n",
    "\n",
    "time.sleep(5)   \n",
    "#creating dataframe\n",
    "df=pd.DataFrame({'Title':repo_title,\n",
    "                'Description':repo_desc,\n",
    "                'Contributors_count':contri_cnt,\n",
    "                'Language_used':lang_used})\n",
    "df\n",
    "\n",
    "## Githib\n",
    "\n",
    "##Bilboard\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.maximize_window()\n",
    "url = \"https:/www.billboard.com/\"\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "try:\n",
    "    hot100 = driver.find_element_by_xpath(\"//a[@class='c-link  lrv-a-unstyle-link lrv-u-color-brand-primary:hover lrv-a-hover-effect lrv-u-whitespace-nowrap lrv-u-color-grey-dark'][1]\")\n",
    "    hot100.click()\n",
    "except WebDriverException:\n",
    "    print(hot100.get_attribute('href'))\n",
    "#  driver.get(hot100.get_attribute('href'))\n",
    "    \n",
    "driver.implicitly_wait(10)    \n",
    "    \n",
    "#scraping song names\n",
    "song_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "    for i in names:\n",
    "        song_name.append(i.text)\n",
    "except NoSuchElementException:       #handling no such element exception\n",
    "    song_name.append('No details available')\n",
    "time.sleep(2)    \n",
    "\n",
    "\n",
    "#scraping artist_names \n",
    "artist_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "    for i in names:\n",
    "        artist_name.append(i.text)\n",
    "except NoSuchElementException:        #handling no such element exception\n",
    "    artist_name.append('No details available')\n",
    "time.sleep(2)\n",
    "    \n",
    "\n",
    "#scraping last week rank\n",
    "last_week_rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "    for i in ranks:\n",
    "        last_week_rank.append(i.text)\n",
    "except NoSuchElementException:        #handling no such element exception\n",
    "    last_week_rank.append('No details available') \n",
    "time.sleep(2)\n",
    "\n",
    "#scraping peak rank\n",
    "peak_rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "    for i in ranks:\n",
    "        peak_rank.append(i.text)\n",
    "except NoSuchElementException:      #handling no such element exception\n",
    "    peak_rank.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping weeks on chart\n",
    "weeks=[]\n",
    "try:\n",
    "    week_count=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "    for i in week_count:\n",
    "        weeks.append(i.text)\n",
    "except NoSuchElementException:          #handling no such element exception\n",
    "    weeks.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#creating dataframe\n",
    "df=pd.DataFrame({'Song_Name':song_name,\n",
    "                'Artist_Name':artist_name,\n",
    "                'Last_week_rank':last_week_rank,\n",
    "                'Peak':peak_rank,\n",
    "                'Weeks_on_chart':weeks})\n",
    "df\n",
    "\n",
    "##Bilboard\n",
    "\n",
    "##IMDB\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.maximize_window()\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "name =[]\n",
    "span =[]\n",
    "genre=[]\n",
    "runtim=[]\n",
    "rat=[]\n",
    "vot =[]\n",
    "\n",
    "name_list = driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/h3/a\")\n",
    "for a in name_list:\n",
    "    name.append(a.text)\n",
    "span_list = driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")    \n",
    "for b in span_list:\n",
    "    span.append(b.text)\n",
    "genre_list = driver.find_elements_by_xpath(\"//span[@class='genre']\")    \n",
    "for c in genre_list:\n",
    "    genre.append(c.text)\n",
    "run_list = driver.find_elements_by_xpath(\"//span[@class='runtime']\")    \n",
    "for d in run_list:\n",
    "    runtim.append(d.text)   \n",
    "rate_list = driver.find_elements_by_xpath(\"//div[@class='ipl-rating-widget']/div/span[2]\")    \n",
    "for e in rate_list:\n",
    "    rat.append(e.text)        \n",
    "vot_list = driver.find_elements_by_xpath(\"//span[@name='nv']\")    \n",
    "for f in vot_list:\n",
    "    vot.append(f.text)\n",
    "\n",
    "if len(name) == len(span) == len(genre) == len(runtim) == len(rat) == len(vot):\n",
    "    df = pd.DataFrame({\"Name\":name,\n",
    "                    \"Year Span\":span,\n",
    "                    \"Genre\":genre,\n",
    "                    \"Run time\":runtim,\n",
    "                    \"Rating\":rat,\n",
    "                    \"Votes\":vot})\n",
    "\n",
    "df\n",
    "##IMDB\n",
    "\n",
    "##ARCHIVE\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.maximize_window()\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "show=driver.find_element_by_xpath(\"//a[@href='datasets.php']\")\n",
    "show.click()\n",
    "time.sleep(1)\n",
    "\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "data_type=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in info[1:]:\n",
    "         data_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    data_type.append(\"No information\")\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping dataset names\n",
    "default_task=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in info[1:]:\n",
    "         default_task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    default_task.append(\"No information\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping dataset names\n",
    "attr_type=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in info[1:]:\n",
    "         attr_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    attr_type.append(\"No information\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping dataset names\n",
    "no_of_instances=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in info[1:]:\n",
    "         no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append(\"No information\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping dataset names\n",
    "no_of_attributes=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in info[1:]:\n",
    "         no_of_attributes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_attributes.append(\"No information\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping dataset names\n",
    "year=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in info[1:]:\n",
    "         year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append(\"No information\")\n",
    "time.sleep(2)\n",
    "\n",
    "#creating dataframe\n",
    "df=pd.DataFrame({'Name':name,\n",
    "                'Data_type':data_type,\n",
    "                'Task':default_task,\n",
    "                'Attribute_type':attr_type,\n",
    "                'No_of_instances':no_of_instances,\n",
    "                'No_of_attributes':no_of_attributes,\n",
    "                'Year':year})\n",
    "df\n",
    "\n",
    "##ARCHIVE\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8de97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
