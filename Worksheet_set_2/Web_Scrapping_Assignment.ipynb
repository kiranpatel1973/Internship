{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fa9d1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************Executing All Funtions***************************************\n",
      "====================================================================================================\n",
      "**********************************************OUTOUT 1**********************************************\n",
      "List of all the h1, h2, h3 :\n",
      "h1 Wikipedia\n",
      "\n",
      "The Free Encyclopedia\n",
      "h2 1 000 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 100 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 10 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 1 000+\n",
      "\n",
      "\n",
      "articles\n",
      "h2 100+\n",
      "\n",
      "\n",
      "articles\n",
      "**********************************************OUTOUT 2**********************************************\n",
      "                             MOVIE NAME RELEASE YEAR RATING\n",
      "0              The Shawshank Redemption         1994    9.3\n",
      "1                         The Godfather         1972    9.2\n",
      "2                The Godfather: Part II         1974      9\n",
      "3                       The Dark Knight         2008      9\n",
      "4                          12 Angry Men         1957      9\n",
      "..                                  ...          ...    ...\n",
      "95                   North by Northwest         1959    8.3\n",
      "96                   A Clockwork Orange         1971    8.3\n",
      "97                               Snatch         2000    8.3\n",
      "98  Le fabuleux destin d'Amélie Poulain         2001    8.3\n",
      "99                              The Kid         1921    8.3\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "**********************************************OUTOUT 3**********************************************\n",
      "                           MOVIE NAME RELEASE YEAR RATING\n",
      "0                     Ship of Theseus         2012      8\n",
      "1                              Iruvar         1997    8.5\n",
      "2                     Kaagaz Ke Phool         1959    7.7\n",
      "3   Lagaan: Once Upon a Time in India         2001    8.1\n",
      "4                     Pather Panchali         1955    8.3\n",
      "..                                ...          ...    ...\n",
      "95                        Apur Sansar         1959    8.5\n",
      "96                        Kanchivaram         2008    8.1\n",
      "97                    Monsoon Wedding         2001    7.3\n",
      "98                              Black         2005    8.1\n",
      "99                            Deewaar         1975      8\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "**********************************************OUTOUT 4**********************************************\n",
      "                                 PRESIDENT NAME                                     TERM OF OFFICE\n",
      "0             Shri Pranab Mukherjee (1935-2020)                    25 July, 2012 to 25 July, 2017 \n",
      "1   Smt Pratibha Devisingh Patil (birth - 1934)                    25 July, 2007 to 25 July, 2012 \n",
      "2            DR. A.P.J. Abdul Kalam (1931-2015)                    25 July, 2002 to 25 July, 2007 \n",
      "3            Shri K. R. Narayanan (1920 - 2005)                    25 July, 1997 to 25 July, 2002 \n",
      "4           Dr Shankar Dayal Sharma (1918-1999)                    25 July, 1992 to 25 July, 1997 \n",
      "5               Shri R Venkataraman (1910-2009)                    25 July, 1987 to 25 July, 1992 \n",
      "6                  Giani Zail Singh (1916-1994)                    25 July, 1982 to 25 July, 1987 \n",
      "7         Shri Neelam Sanjiva Reddy (1913-1996)                    25 July, 1977 to 25 July, 1982 \n",
      "8          Dr. Fakhruddin Ali Ahmed (1905-1977)               24 August, 1974 to 11 February, 1977\n",
      "9      Shri Varahagiri Venkata Giri (1894-1980)  3 May, 1969 to 20 July, 1969 and 24 August, 19...\n",
      "10                 Dr. Zakir Husain (1897-1969)                        13 May, 1967 to 3 May, 1969\n",
      "11     Dr. Sarvepalli Radhakrishnan (1888-1975)                       13 May, 1962 to 13 May, 1967\n",
      "12             Dr. Rajendra Prasad (1884-1963)                    26 January, 1950 to 13 May, 1962\n",
      "**********************************************OUTOUT 5**********************************************\n",
      "  Position              Team Matches Points Ratings\n",
      "0        1   New Zealand(NZ)      12  1,505     125\n",
      "1        2      England(ENG)      19     19     124\n",
      "2        3    Australia(AUS)      18     18     107\n",
      "3        4        India(IND)      22     22     105\n",
      "4        5     Pakistan(PAK)      16     16     102\n",
      "5        6  South Africa(SA)      19     19      99\n",
      "6        7   Bangladesh(BAN)      24     24      95\n",
      "7        8     Sri Lanka(SL)      24     24      87\n",
      "8        9   West Indies(WI)      26     26      73\n",
      "9       10  Afghanistan(AFG)      15     15      66\n",
      "  Position                   Name Team Rating\n",
      "0        1             Babar Azam  PAK    891\n",
      "1        2            Virat Kohli  IND    811\n",
      "2        3            Imam-ul-Haq  PAK    795\n",
      "3        4           Rohit Sharma  IND    791\n",
      "4        5        Quinton de Kock   SA    789\n",
      "5        6         Jonny Bairstow  ENG    775\n",
      "6        7            Ross Taylor   NZ    775\n",
      "7        8  Rassie van der Dussen   SA    769\n",
      "8        9           David Warner  AUS    750\n",
      "9       10            Aaron Finch  AUS    745\n",
      "  Position              Name Team Rating\n",
      "0        1       Trent Boult   NZ    726\n",
      "1        2      Chris Woakes  ENG    700\n",
      "2        3    Josh Hazlewood  AUS    698\n",
      "3        4        Matt Henry   NZ    683\n",
      "4        5  Mujeeb Ur Rahman  AFG    681\n",
      "5        6    Jasprit Bumrah  IND    679\n",
      "6        7    Shaheen Afridi  PAK    671\n",
      "7        8      Mehedi Hasan  BAN    661\n",
      "8        9   Shakib Al Hasan  BAN    657\n",
      "9       10       Rashid Khan  AFG    650\n",
      "**********************************************OUTOUT 6**********************************************\n",
      "  Position              Team Matches Points Ratings\n",
      "0        1    Australia(AUS)      29  4,840     167\n",
      "1        2  South Africa(SA)      28     28     125\n",
      "2        3      England(ENG)      30     30     118\n",
      "3        4        India(IND)      29     29      99\n",
      "4        5   New Zealand(NZ)      31     31      98\n",
      "5        6   West Indies(WI)      28     28      89\n",
      "6        7   Bangladesh(BAN)      12     12      78\n",
      "7        8     Pakistan(PAK)      26     26      67\n",
      "8        9      Ireland(IRE)       5      5      48\n",
      "9       10     Sri Lanka(SL)       5      5      47\n",
      "  Position               Name Team Rating\n",
      "0        1       Alyssa Healy  AUS    785\n",
      "1        2     Natalie Sciver  ENG    750\n",
      "2        3        Beth Mooney  AUS    748\n",
      "3        4    Laura Wolvaardt   SA    722\n",
      "4        5        Meg Lanning  AUS    710\n",
      "5        6     Rachael Haynes  AUS    701\n",
      "6        7        Mithali Raj  IND    686\n",
      "7        8  Amy Satterthwaite   NZ    681\n",
      "8        9    Smriti Mandhana  IND    669\n",
      "9       10     Tammy Beaumont  ENG    659\n",
      "  Position              Name Team Rating\n",
      "0        1    Natalie Sciver  ENG    393\n",
      "1        2      Ellyse Perry  AUS    374\n",
      "2        3    Marizanne Kapp   SA    359\n",
      "3        4   Hayley Matthews   WI    338\n",
      "4        5       Amelia Kerr   NZ    335\n",
      "5        6  Ashleigh Gardner  AUS    269\n",
      "6        7     Deepti Sharma  IND    249\n",
      "7        8     Jess Jonassen  AUS    245\n",
      "8        9   Katherine Brunt  ENG    221\n",
      "9       10    Jhulan Goswami  IND    217\n",
      "**********************************************Output 7**********************************************\n",
      "                                             Headline         Time                                          News Link\n",
      "0   Santoli: Stocks digest last week's rally, as t...   12 Min Ago  https://www.cnbc.com/2022/05/31/santoli-stocks...\n",
      "1   House Democrats aim to pass gun control legisl...   40 Min Ago  https://www.cnbc.com/2022/05/31/house-democrat...\n",
      "2   These 'quality cyclical' stocks are due for a ...   53 Min Ago  https://www.cnbc.com/2022/05/31/these-quality-...\n",
      "3   We're buying more shares of this beverage comp...   59 Min Ago  https://www.cnbc.com/2022/05/31/were-buying-mo...\n",
      "4   Beware of these dollar-vulnerable stocks if th...   1 Hour Ago  https://www.cnbc.com/2022/05/31/beware-of-thes...\n",
      "5   Pay freeze vs. returning to office: Workers eq...   1 Hour Ago  https://www.cnbc.com/2022/05/31/a-pay-freeze-v...\n",
      "6   Feeling behind on retirement savings? These ti...  2 Hours Ago  https://www.cnbc.com/2022/05/31/these-tips-can...\n",
      "7   These 5 skills are seeing huge growth in deman...  2 Hours Ago  https://www.cnbc.com/2022/05/31/in-demand-five...\n",
      "8   Medicare Part B premium reduction won’t happen...  2 Hours Ago  https://www.cnbc.com/2022/05/31/medicare-part-...\n",
      "9   Gas prices and inflation top summer travel wor...  3 Hours Ago  https://www.cnbc.com/2022/05/31/gas-prices-and...\n",
      "10  Britain plans safeguards for stablecoins that ...  3 Hours Ago  https://www.cnbc.com/2022/05/31/uk-plans-new-s...\n",
      "11  Apple's iPhone manufacturer says supply chain ...  3 Hours Ago  https://www.cnbc.com/2022/05/31/apples-iphone-...\n",
      "12  These key data points may determine whether th...  4 Hours Ago  https://www.cnbc.com/2022/05/31/these-are-the-...\n",
      "13  Israel signs historic trade deal with UAE, its...  4 Hours Ago  https://www.cnbc.com/2022/05/31/israel-signs-t...\n",
      "14  Apple's new iPhone and iPad software will repo...  4 Hours Ago  https://www.cnbc.com/2022/05/31/apple-ios-16-i...\n",
      "15  British pound is taking on 'emerging market' c...  4 Hours Ago  https://www.cnbc.com/2022/05/31/sterling-is-ta...\n",
      "16  This 5-minute email hack can help you stand ou...  4 Hours Ago  https://www.cnbc.com/2022/05/31/this-5-minute-...\n",
      "17  What Cramer is watching Tuesday — bull in a be...  4 Hours Ago  https://www.cnbc.com/2022/05/31/cramer-tuesday...\n",
      "18  Home prices surged over 20% in March, S&P Case...  4 Hours Ago  https://www.cnbc.com/2022/05/31/home-prices-su...\n",
      "19  As employers call workers back to the office, ...  4 Hours Ago  https://www.cnbc.com/2022/05/31/as-employers-c...\n",
      "20  Don't make these 11 punctuation mistakes that ...  4 Hours Ago  https://www.cnbc.com/2022/05/31/sound-smarter-...\n",
      "21  Don't sound the all-clear in stocks just yet, ...  5 Hours Ago  https://www.cnbc.com/2022/05/31/dont-sound-the...\n",
      "22  What to watch today: Stock futures are lower a...  5 Hours Ago  https://www.cnbc.com/2022/05/31/what-to-watch-...\n",
      "23  Tuesday's biggest analyst calls: Tesla, Dish, ...  5 Hours Ago  https://www.cnbc.com/2022/05/31/tuesday-top-wa...\n",
      "24  5 things to know before the stock market opens...  5 Hours Ago  https://www.cnbc.com/2022/05/31/5-things-to-kn...\n",
      "25  Dish shares can more than double from here, Tr...  5 Hours Ago  https://www.cnbc.com/2022/05/31/buy-dish-as-st...\n",
      "26  Stocks making the biggest moves premarket: Yam...  6 Hours Ago  https://www.cnbc.com/2022/05/31/stocks-making-...\n",
      "27  Nio is poised for a comeback as China lockdown...  6 Hours Ago  https://www.cnbc.com/2022/05/31/this-electric-...\n",
      "28  Britain urges people with monkeypox to abstain...  6 Hours Ago  https://www.cnbc.com/2022/05/31/britain-urges-...\n",
      "29  Morgan Stanley downgrades American Eagle, sees...  7 Hours Ago  https://www.cnbc.com/2022/05/31/morgan-stanley...\n",
      "**********************************************OUTOUT 8**********************************************\n",
      "                                                Title                                            Authors  Published Date                                          Paper URL\n",
      "0                                    Reward is enough  Silver, David, Singh, Satinder, Precup, Doina,...    October 2021  https://www.sciencedirect.com/science/article/...\n",
      "1                           Making sense of raw input          Evans, Richard, Bošnjak, Matko and 5 more    October 2021  https://www.sciencedirect.com/science/article/...\n",
      "2   Law and logic: A review from an argumentation ...                  Prakken, Henry, Sartor, Giovanni     October 2015  https://www.sciencedirect.com/science/article/...\n",
      "3              Creativity and artificial intelligence                                Boden, Margaret A.      August 1998  https://www.sciencedirect.com/science/article/...\n",
      "4   Artificial cognition for social human–robot in...    Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017  https://www.sciencedirect.com/science/article/...\n",
      "5   Explanation in artificial intelligence: Insigh...                                       Miller, Tim    February 2019  https://www.sciencedirect.com/science/article/...\n",
      "6                       Making sense of sensory input  Evans, Richard, Hernández-Orallo, José and 3 more      April 2021  https://www.sciencedirect.com/science/article/...\n",
      "7   Conflict-based search for optimal multi-agent ...  Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015  https://www.sciencedirect.com/science/article/...\n",
      "8   Between MDPs and semi-MDPs: A framework for te...  Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999  https://www.sciencedirect.com/science/article/...\n",
      "9   The Hanabi challenge: A new frontier for AI re...        Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020  https://www.sciencedirect.com/science/article/...\n",
      "10  Evaluating XAI: A comparison of rule-based and...  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021  https://www.sciencedirect.com/science/article/...\n",
      "11           Argumentation in artificial intelligence               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007  https://www.sciencedirect.com/science/article/...\n",
      "12  Algorithms for computing strategies in two-pla...       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016  https://www.sciencedirect.com/science/article/...\n",
      "13      Multiple object tracking: A literature review             Luo, Wenhan, Xing, Junliang and 4 more      April 2021  https://www.sciencedirect.com/science/article/...\n",
      "14  Selection of relevant features and examples in...                      Blum, Avrim L., Langley, Pat    December 1997  https://www.sciencedirect.com/science/article/...\n",
      "15  A survey of inverse reinforcement learning: Ch...                   Arora, Saurabh, Doshi, Prashant      August 2021  https://www.sciencedirect.com/science/article/...\n",
      "16  Explaining individual predictions when feature...      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021  https://www.sciencedirect.com/science/article/...\n",
      "17  A review of possible effects of cognitive bias...  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021  https://www.sciencedirect.com/science/article/...\n",
      "18  Integrating social power into the decision-mak...    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016  https://www.sciencedirect.com/science/article/...\n",
      "19  “That's (not) the output I expected!” On the r...                      Riveiro, Maria, Thill, Serge   September 2021  https://www.sciencedirect.com/science/article/...\n",
      "20  Explaining black-box classifiers using post-ho...  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021  https://www.sciencedirect.com/science/article/...\n",
      "21  Algorithm runtime prediction: Methods & evalua...  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014  https://www.sciencedirect.com/science/article/...\n",
      "22              Wrappers for feature subset selection                      Kohavi, Ron, John, George H.    December 1997  https://www.sciencedirect.com/science/article/...\n",
      "23  Commonsense visual sensemaking for autonomous ...  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021  https://www.sciencedirect.com/science/article/...\n",
      "24         Quantum computation, quantum theory and AI                                   Ying, Mingsheng    February 2010  https://www.sciencedirect.com/science/article/...\n",
      "**********************************************OUTOUT 9**********************************************\n",
      "                   Restaurant Name                                         Cusine                                           Location Ratings                                         Images URL\n",
      "0                      Episode One           Finger Food, Asian, Italian, Chinese                       Delphi Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "1                       Pop Tate's                Continental, Chinese, Fast Food  Mayfair Sonata Green CHS,Vikhroli West, Centra...   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "2                       Pop Tate's                Continental, Chinese, Fast Food        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "3              Sigree Global Grill                          North Indian, Biryani                      Ventura Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "4               Lord of the Drinks         Chinese, European, Asian, North Indian                                       Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "5                          Hitchki                        North Indian, Fast Food        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "6         ABs - Absolute Barbecues                                   North Indian                                  Chandivali, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "7                      Urban Tadka                          North Indian, Mughlai        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "8                          Hitchki                        North Indian, Fast Food             Hiranandani Business Park,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "9                   Mainland China                           Chinese, Asian, Thai                                 Hiranandani, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "10               Khandani Rajdhani             Gujarati, Rajasthani, North Indian        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "11                    PizzaExpress                      Italian, Pizza, Beverages                      Ventura Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "12              The Butter Kitchen                                   North Indian                      Ventura Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "13                 The Sassy Spoon                          Continental, European                       Delphi Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "14                       Timbuctoo    Finger Food, Chinese, Italian, North Indian  Mayfair Sonata Green CHS,Vikhroli West, Centra...   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "15  Chili’s American Grill and Bar                     American, Mexican, Tex Mex                      Ventura Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "16                True Tramm Trunk                                    Finger Food                                  Chandivali, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "17               House of Mandarin                                          Asian                       Delphi Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "18                    Powai Social   North Indian, Chinese, American, Continental                       Delphi Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "19                   Kake Da Hotel                 Chinese, North Indian, Biryani                                       Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "20                 Finch Brew Cafe                      Continental, North Indian                    City Park Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "*********************************************OUTOUT 10**********************************************\n",
      "   Serial                                               Name H5-Index H5-Median\n",
      "0      1.                                             Nature      414       607\n",
      "1      2.                The New England Journal of Medicine      410       704\n",
      "2      3.                                            Science      391       564\n",
      "3      4.  IEEE/CVF Conference on Computer Vision and Pat...      356       583\n",
      "4      5.                                         The Lancet      345       600\n",
      "..    ...                                                ...      ...       ...\n",
      "95    96.                            Frontiers in Immunology      134       177\n",
      "96    97.                                              Small      134       173\n",
      "97    98.                                  Nature Immunology      133       210\n",
      "98    99.                                      JAMA Oncology      133       202\n",
      "99   100.                               The Lancet Neurology      133       200\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "*************************************ENJOYED SCRAPPING THE WEB**************************************\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "url1  = 'https://www.wikipedia.org/'\n",
    "url2  = 'https://www.imdb.com/list/ls091520106/'\n",
    "url3  = 'https://www.imdb.com/list/ls056092300/'\n",
    "url4  = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "url51 = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "url52 = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "url53 = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "url61 = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi' \n",
    "url62 = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "url63 = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "url7  = 'https://www.cnbc.com/world/?region=world'\n",
    "url8  = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "url9  = 'https://www.dineout.co.in/mumbai-restaurants/welcome-back'\n",
    "url10 = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "\n",
    "\n",
    "## 1 Funtion to print all the header tags from wikipedia.org.\n",
    "def wiki_header(url):\n",
    "    reqs = requests.get(url)\n",
    "    soup = bs(reqs.text, 'lxml')\n",
    "    print(\"List of all the h1, h2, h3 :\")\n",
    "    for heading in soup.find_all([\"h1\", \"h2\", \"h3\"]): \n",
    "        print(heading.name + ' ' + heading.text.strip())\n",
    "## 1 Funtion to print all the header tags from wikipedia.org.\n",
    "\n",
    "## 2 IMDB’s Top rated 100 movies\n",
    "def imdb_top_100(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    soup = bs(reqs.content,'html.parser')\n",
    "    \n",
    "    movie_name =[]\n",
    "    release_year =[]\n",
    "    movie_rating =[]\n",
    "    movie_data = soup.find_all('div',attrs={'class':'lister-item mode-detail'})\n",
    "    for x in movie_data:\n",
    "        name = x.h3.a.text\n",
    "        movie_name.append(name)\n",
    "    \n",
    "        yr_of_rel = x.h3.find('span',class_='lister-item-year text-muted unbold').text.replace('(','').replace(')','')\n",
    "        release_year.append(yr_of_rel)\n",
    "    \n",
    "        rate = x.find('span',class_ ='ipl-rating-star__rating').text\n",
    "        movie_rating.append(rate)\n",
    "    \n",
    "    mdb_top100_df = pd.DataFrame({'MOVIE NAME':movie_name,'RELEASE YEAR':release_year,'RATING':movie_rating})\n",
    "    print(mdb_top100_df)\n",
    "## 2 IMDB’s Top rated 100 movies\n",
    "\n",
    "## 3 IMDB’s Top rated 100 Indian movies’ data\n",
    "def imdb_ind_top_100(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    soup = bs(reqs.content,'html.parser')\n",
    "    movie_name = []\n",
    "    release_year =[]\n",
    "    movie_rating =[]\n",
    "\n",
    "    movie_data = soup.find_all('div',attrs={'class':'lister-item mode-detail'})\n",
    "\n",
    "    for x in movie_data:\n",
    "        name = x.h3.a.text\n",
    "        movie_name.append(name)\n",
    "    \n",
    "        yr_of_rel = x.h3.find('span',class_='lister-item-year text-muted unbold').text.replace('(','').replace(')','')\n",
    "        release_year.append(yr_of_rel)\n",
    "    \n",
    "        rate = x.find('span',class_ ='ipl-rating-star__rating').text\n",
    "        movie_rating.append(rate)\n",
    "    \n",
    "    mdb_top100_df = pd.DataFrame({'MOVIE NAME':movie_name,'RELEASE YEAR':release_year,'RATING':movie_rating})\n",
    "    print(mdb_top100_df)\n",
    "## 3 IMDB’s Top rated 100 Indian movies’ data\n",
    "\n",
    "## 4 List of Respected Former Presidents of India\n",
    "def ind_presi_list(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    soup = bs(reqs.content,'html.parser')\n",
    "\n",
    "    all_data = soup.find('ul',class_=\"listing cf\").find_all(\"li\")\n",
    "    name = []\n",
    "    term = []\n",
    "\n",
    "    for x in all_data:\n",
    "        nam = x.h3.text\n",
    "        name.append(nam)\n",
    "    \n",
    "        ter = x.p.text.replace('Term of Office: ','')\n",
    "        term.append(ter)\n",
    "    \n",
    "    mdb_indpresi_df = pd.DataFrame({'PRESIDENT NAME':name,'TERM OF OFFICE':term})\n",
    "    print(mdb_indpresi_df)\n",
    "## 4 List Of Respected Former Presidents of India\n",
    "\n",
    "## 5 MEN ODI RANKING\n",
    "def icc_mens_rankings(url1,url2,url3):\n",
    "    response1 = requests.get(url1)\n",
    "    response2 = requests.get(url2)\n",
    "    response3 = requests.get(url3)\n",
    "\n",
    "    odi_pos =[]\n",
    "    odi_team =[]\n",
    "    odi_matches =[]\n",
    "    odi_points=[]\n",
    "    odi_ratings=[]\n",
    "\n",
    "    soup1 = bs(response1.content,'html.parser')\n",
    "\n",
    "    all_data1 = soup1.find_all('div',attrs={'class':'rankings-block__container full rankings-table'})\n",
    "    all_data2 = soup1.find_all('tr',class_=\"table-body\")\n",
    "\n",
    "    for x in all_data1:\n",
    "        rank = x.find('td',class_ ='rankings-block__banner--pos').text\n",
    "        odi_pos.append(rank)\n",
    "        team = x.find('span',class_='u-hide-phablet').text\n",
    "        team_abb = x.find('span',class_='u-show-phablet').text\n",
    "        odi_team.append(team+'('+team_abb+')')\n",
    "        matches = x.find('td',class_='rankings-block__banner--matches').text\n",
    "        odi_matches.append(matches)\n",
    "        point = x.find('td',class_='rankings-block__banner--points').text\n",
    "        odi_points.append(point)\n",
    "        ratings = x.find('td',class_='rankings-block__banner--rating u-text-right').text.replace('\\n','').replace(\" \",\"\")\n",
    "        odi_ratings.append(ratings)\n",
    "\n",
    "    for y in all_data2:\n",
    "        if len(odi_pos) < 10:\n",
    "            ra = y.find('td',class_='table-body__cell table-body__cell--position u-text-right').text\n",
    "            odi_pos.append(ra)\n",
    "            te = y.find('span',class_='u-hide-phablet').text\n",
    "            te_abb = y.find('span',class_='u-show-phablet').text\n",
    "            odi_team.append(te+'('+te_abb+')')   \n",
    "            ma = y.find('td',class_='table-body__cell u-center-text').text  ## tag for matches and points and exactly similar\n",
    "            odi_matches.append(ma)\n",
    "            po = y.find('td',class_='table-body__cell u-center-text').text  ## tag for matches and points and exactly similar\n",
    "            odi_points.append(po)\n",
    "            ra = y.find('td',class_='table-body__cell u-text-right rating').text.replace('\\n','').replace(\" \",\"\")\n",
    "            odi_ratings.append(ra)\n",
    "    \n",
    "    top_10_df = pd.DataFrame({'Position':odi_pos,'Team':odi_team,'Matches':odi_matches,'Points':odi_points,'Ratings':odi_ratings})\n",
    "\n",
    "### top 10 odi batsmen - url2\n",
    "    soup2 = bs(response2.content,'html.parser')\n",
    "\n",
    "    ply_pos = []\n",
    "    ply_nam = []\n",
    "    ply_tem = []\n",
    "    ply_rat = []\n",
    "\n",
    "    all_data3 = soup2.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    all_data4 = soup2.find_all('tr',class_=\"table-body\")\n",
    "\n",
    "    for a in all_data3:\n",
    "        plypos = a.find('span',class_='rankings-block__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "        ply_pos.append(plypos)\n",
    "        plynam = a.find('div',class_='rankings-block__banner--name-large').text\n",
    "        ply_nam.append(plynam)\n",
    "        plytem = a.find('div',class_='rankings-block__banner--nationality').text.replace('\\n',\"\")\n",
    "        ply_tem.append(plytem)\n",
    "        plyrat = a.find('div',class_='rankings-block__banner--rating').text\n",
    "        ply_rat.append(plyrat)\n",
    "\n",
    "    for b in all_data4:\n",
    "        if len(ply_pos) < 10:\n",
    "            plypos1 = b.find('span',class_='rankings-table__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "            ply_pos.append(plypos1)\n",
    "            plynam1 = b.find('td',class_='table-body__cell rankings-table__name name').text.replace('\\n',\"\")\n",
    "            ply_nam.append(plynam1)\n",
    "            plytem1 = b.find('span',class_='table-body__logo-text').text\n",
    "            ply_tem.append(plytem1)\n",
    "            plyrat1 = b.find('td',class_='table-body__cell rating').text\n",
    "            ply_rat.append(plyrat1)\n",
    "        \n",
    "    top10_odi_bat = pd.DataFrame({'Position':ply_pos,'Name':ply_nam,'Team':ply_tem,'Rating':ply_rat})  \n",
    "\n",
    "### top 10 odi bowler - url3\n",
    "    soup3 = bs(response3.content,'html.parser')\n",
    "    blw_pos = []\n",
    "    blw_nam = []\n",
    "    blw_tem = []\n",
    "    blw_rat = []\n",
    "\n",
    "    all_data5 = soup3.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    all_data6 = soup3.find_all('tr',class_=\"table-body\")\n",
    "\n",
    "    for c in all_data5:\n",
    "        blwpos = c.find('span',class_='rankings-block__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "        blw_pos.append(blwpos)\n",
    "        blwnam = c.find('div',class_='rankings-block__banner--name-large').text\n",
    "        blw_nam.append(blwnam)\n",
    "        blwtem = c.find('div',class_='rankings-block__banner--nationality').text.replace('\\n',\"\")\n",
    "        blw_tem.append(blwtem)\n",
    "        blwrat = c.find('div',class_='rankings-block__banner--rating').text\n",
    "        blw_rat.append(blwrat)\n",
    "    \n",
    "    for d in all_data6:\n",
    "        if len(blw_pos) < 10:\n",
    "            blwpos1 = d.find('span',class_='rankings-table__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "            blw_pos.append(blwpos1)\n",
    "            blwnam1 = d.find('td',class_='table-body__cell rankings-table__name name').text.replace('\\n',\"\")\n",
    "            blw_nam.append(blwnam1)\n",
    "            blwtem1 = d.find('span',class_='table-body__logo-text').text\n",
    "            blw_tem.append(blwtem1)\n",
    "            blwrat1 = d.find('td',class_='table-body__cell rating').text\n",
    "            blw_rat.append(blwrat1)   \n",
    "        \n",
    "    top10_odi_blw = pd.DataFrame({'Position':blw_pos,'Name':blw_nam,'Team':blw_tem,'Rating':blw_rat})  \n",
    "    print(top_10_df)\n",
    "    print(top10_odi_bat)\n",
    "    print(top10_odi_blw) \n",
    "## 5 MEN ODI RANKING\n",
    "\n",
    "## 6 WOMEN ODI RANKING\n",
    "def icc_womens_rankings(url1,url2,url3):\n",
    "    response1 = requests.get(url1)\n",
    "    response2 = requests.get(url2)\n",
    "    response3 = requests.get(url3)\n",
    "\n",
    "    odi_pos =[]\n",
    "    odi_team =[]\n",
    "    odi_matches =[]\n",
    "    odi_points=[]\n",
    "    odi_ratings=[]\n",
    "\n",
    "    soup1 = bs(response1.content,'html.parser')\n",
    "\n",
    "    all_data1 = soup1.find_all('div',attrs={'class':'rankings-block__container full rankings-table'})\n",
    "    all_data2 = soup1.find_all('tr',class_=\"table-body\")\n",
    "### top 10 odi team - url1\n",
    "    for x in all_data1:\n",
    "        rank = x.find('td',class_ ='rankings-block__banner--pos').text\n",
    "        odi_pos.append(rank)\n",
    "        team = x.find('span',class_='u-hide-phablet').text\n",
    "        team_abb = x.find('span',class_='u-show-phablet').text\n",
    "        odi_team.append(team+'('+team_abb+')')\n",
    "        matches = x.find('td',class_='rankings-block__banner--matches').text\n",
    "        odi_matches.append(matches)\n",
    "        point = x.find('td',class_='rankings-block__banner--points').text\n",
    "        odi_points.append(point)\n",
    "        ratings = x.find('td',class_='rankings-block__banner--rating u-text-right').text.replace('\\n','').replace(\" \",\"\")\n",
    "        odi_ratings.append(ratings)\n",
    "\n",
    "    for y in all_data2:\n",
    "        if len(odi_pos) < 10:\n",
    "            ra = y.find('td',class_='table-body__cell table-body__cell--position u-text-right').text\n",
    "            odi_pos.append(ra)\n",
    "            te = y.find('span',class_='u-hide-phablet').text\n",
    "            te_abb = y.find('span',class_='u-show-phablet').text\n",
    "            odi_team.append(te+'('+te_abb+')')   \n",
    "            ma = y.find('td',class_='table-body__cell u-center-text').text  ## tag for matches and points and exactly similar\n",
    "            odi_matches.append(ma)\n",
    "            po = y.find('td',class_='table-body__cell u-center-text').text  ## tag for matches and points and exactly similar\n",
    "            odi_points.append(po)\n",
    "            ra = y.find('td',class_='table-body__cell u-text-right rating').text.replace('\\n','').replace(\" \",\"\")\n",
    "            odi_ratings.append(ra)\n",
    "    \n",
    "    top_10_df = pd.DataFrame({'Position':odi_pos,'Team':odi_team,'Matches':odi_matches,'Points':odi_points,'Ratings':odi_ratings})\n",
    "        \n",
    "### top 10 odi batsmen - url2\n",
    "    soup2 = bs(response2.content,'html.parser')\n",
    "    ply_pos = []\n",
    "    ply_nam = []\n",
    "    ply_tem = []\n",
    "    ply_rat = []\n",
    "\n",
    "    all_data3 = soup2.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    all_data4 = soup2.find_all('tr',class_=\"table-body\")\n",
    "\n",
    "    for a in all_data3:\n",
    "        plypos = a.find('span',class_='rankings-block__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "        ply_pos.append(plypos)\n",
    "        plynam = a.find('div',class_='rankings-block__banner--name-large').text\n",
    "        ply_nam.append(plynam)\n",
    "        plytem = a.find('div',class_='rankings-block__banner--nationality').text.replace('\\n',\"\")\n",
    "        ply_tem.append(plytem)\n",
    "        plyrat = a.find('div',class_='rankings-block__banner--rating').text\n",
    "        ply_rat.append(plyrat)\n",
    "\n",
    "    for b in all_data4:\n",
    "        if len(ply_pos) < 10:\n",
    "            plypos1 = b.find('span',class_='rankings-table__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "            ply_pos.append(plypos1)\n",
    "            plynam1 = b.find('td',class_='table-body__cell rankings-table__name name').text.replace('\\n',\"\")\n",
    "            ply_nam.append(plynam1)\n",
    "            plytem1 = b.find('span',class_='table-body__logo-text').text\n",
    "            ply_tem.append(plytem1)\n",
    "            plyrat1 = b.find('td',class_='table-body__cell rating').text\n",
    "            ply_rat.append(plyrat1)\n",
    "        \n",
    "    top10_odi_bat = pd.DataFrame({'Position':ply_pos,'Name':ply_nam,'Team':ply_tem,'Rating':ply_rat})  \n",
    "### top 10 odi all rounder - url3\n",
    "    soup3 = bs(response3.content,'html.parser')\n",
    "    blw_pos = []\n",
    "    blw_nam = []\n",
    "    blw_tem = []\n",
    "    blw_rat = []\n",
    "\n",
    "    all_data5 = soup3.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    all_data6 = soup3.find_all('tr',class_=\"table-body\")\n",
    "\n",
    "    for c in all_data5:\n",
    "        blwpos = c.find('span',class_='rankings-block__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "        blw_pos.append(blwpos)\n",
    "        blwnam = c.find('div',class_='rankings-block__banner--name-large').text\n",
    "        blw_nam.append(blwnam)\n",
    "        blwtem = c.find('div',class_='rankings-block__banner--nationality').text.replace('\\n',\"\")\n",
    "        blw_tem.append(blwtem)\n",
    "        blwrat = c.find('div',class_='rankings-block__banner--rating').text\n",
    "        blw_rat.append(blwrat)\n",
    "    \n",
    "    for d in all_data6:\n",
    "        if len(blw_pos) < 10:\n",
    "            blwpos1 = d.find('span',class_='rankings-table__pos-number').text.replace('\\n',\"\").replace(\" \",\"\")\n",
    "            blw_pos.append(blwpos1)\n",
    "            blwnam1 = d.find('td',class_='table-body__cell rankings-table__name name').text.replace('\\n',\"\")\n",
    "            blw_nam.append(blwnam1)\n",
    "            blwtem1 = d.find('span',class_='table-body__logo-text').text\n",
    "            blw_tem.append(blwtem1)\n",
    "            blwrat1 = d.find('td',class_='table-body__cell rating').text\n",
    "            blw_rat.append(blwrat1)   \n",
    "        \n",
    "    top10_odi_blw = pd.DataFrame({'Position':blw_pos,'Name':blw_nam,'Team':blw_tem,'Rating':blw_rat})\n",
    "    print(top_10_df)\n",
    "    print(top10_odi_bat)\n",
    "    print(top10_odi_blw)\n",
    "## 6 WOMEN ODI RANKING\n",
    "\n",
    "## 7 CNBC News Details\n",
    "def news_details(url_name):\n",
    "    response = requests.get(url_name)\n",
    "    soup = bs(response.content,'lxml')\n",
    "\n",
    "    all_news = soup.find('ul',class_='LatestNews-list').find_all('li',class_='LatestNews-item')\n",
    "\n",
    "    headline = []\n",
    "    time = []\n",
    "    newslink =[]\n",
    "\n",
    "    for x in all_news:\n",
    "        ts = x.find('time',class_='LatestNews-timestamp').text\n",
    "        time.append(ts)\n",
    "        ti = x.find('div',class_='LatestNews-headlineWrapper').text\n",
    "        ti = ti.replace(ts, \"\") \n",
    "        headline.append(ti)\n",
    "        li = x.find('a',attrs={'href': re.compile(\"^https://\")}).get('href') \n",
    "        newslink.append(li)\n",
    "    \n",
    "    news_det_df = pd.DataFrame({'Headline':headline,'Time':time,'News Link':newslink})    \n",
    "    print(news_det_df)\n",
    "## 7 CNBC News Details\n",
    "\n",
    "## 8 Most Download Artices on AI\n",
    "def most_dwn_articles(url_name):\n",
    "    res = requests.get(url_name)\n",
    "    soup = bs(res.content,'html.parser')\n",
    "\n",
    "    all_data = soup.find('ul',class_='sc-9zxyh7-0 ffmPq').find_all('li',class_='sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp')\n",
    "\n",
    "    t_list =[]\n",
    "    a_list =[]\n",
    "    p_list =[]\n",
    "    u_list =[]\n",
    "\n",
    "    for x in all_data:\n",
    "        title = x.find('h2',class_='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR').text\n",
    "        t_list.append(title)\n",
    "        authors = x.find('span',class_='sc-1w3fpd7-0 pgLAT').text\n",
    "        a_list.append(authors)\n",
    "        pubdt   = x.find('span',class_='sc-1thf9ly-2 bKddwo').text\n",
    "        p_list.append(pubdt)\n",
    "        purl    = x.find('a').get('href')\n",
    "        u_list.append(purl)\n",
    "    \n",
    "    dwn_df = pd.DataFrame({'Title':t_list,'Authors':a_list,'Published Date':p_list,'Paper URL':u_list})    \n",
    "    print(dwn_df)\n",
    "## 8 Most Download Artices on AI\n",
    "\n",
    "## 9 Dine-Out\n",
    "\n",
    "def dine_out(url_name):\n",
    "    req  = requests.get(url_name)\n",
    "    soup = bs(req.content,'lxml')\n",
    "    \n",
    "    name_list = []\n",
    "    cusine_list =[]\n",
    "    location_list =[]\n",
    "    ratings_list =[]\n",
    "    images_url_list =[]\n",
    "\n",
    "    all_rest_data = soup.find('div',class_='restnt-card-wrap-new')\n",
    "    \n",
    "    for det in all_rest_data:\n",
    "        name = det.find('a').text\n",
    "        name_list.append(name)\n",
    "        cus = det.find('span',class_='double-line-ellipsis').text.split('|') \n",
    "        cus[1]\n",
    "              ## cus[0] is ₹ 1,200 for 2 (approx) \n",
    "              ## cus[1] is Continental, North Indian cusine\n",
    "        cusine_list.append(cus[1])\n",
    "        loc = det.find('div',class_='restnt-loc ellipsis').text\n",
    "        location_list.append(loc)\n",
    "        images = det.find('img',class_='no-img').get('data-src')\n",
    "        images_url_list.append(images)\n",
    "        rat = det.find('div',class_='restnt-rating rating-4 hide') ## not able to derive the ratings correctly\n",
    "        ratings_list.append(rat)\n",
    "\n",
    "    dineout_df = pd.DataFrame({'Restaurant Name':name_list,'Cusine':cusine_list,'Location':location_list,'Ratings':ratings_list,'Images URL':images_url_list})\n",
    "    print(dineout_df)\n",
    "## 9 Dine-Out\n",
    "\n",
    "## 10 Top publications from Google Scholar\n",
    "def goog_publ(url_name):\n",
    "    response = requests.get(url_name)\n",
    "    soup = bs(response.content,'html.parser')\n",
    "\n",
    "    all_publi1 = soup.find_all('td',{'class': 'gsc_mvt_p'}) \n",
    "    r_list =[]\n",
    "    for det in all_publi1:\n",
    "        r_list.append(det.text)\n",
    "\n",
    "    all_publi2 = soup.find_all('td',{'class': 'gsc_mvt_t'})    \n",
    "    p_list =[]\n",
    "    for det in all_publi2:\n",
    "        p_list.append(det.text)\n",
    "\n",
    "    all_publi3 = soup.find_all('td',{'class': 'gsc_mvt_n'})\n",
    "    h5i_list=[]\n",
    "    for det in all_publi3:\n",
    "        if det.find('a'):\n",
    "            h5i_list.append(det.text)\n",
    "\n",
    "    all_publi4 = soup.find_all('td',{'class': 'gsc_mvt_n'})    \n",
    "    h5m_list=[]\n",
    "    for det in all_publi4:\n",
    "         if det.find('span',class_='gs_ibl gsc_mp_anchor'):\n",
    "                h5m_list.append(det.text)\n",
    "\n",
    "    goo_pub_df = pd.DataFrame({'Serial':r_list,'Name':p_list,'H5-Index':h5i_list,'H5-Median':h5m_list})\n",
    "    print(goo_pub_df)\n",
    "## 10 Top publications from Google Scholar\n",
    "\n",
    "print('{:*^100}'.format('Executing All Funtions'))\n",
    "print('{:=^100}'.format('='))\n",
    "print('{:*^100}'.format('OUTOUT 1'))\n",
    "wiki_header(url1)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('OUTOUT 2'))\n",
    "imdb_top_100(url2)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('OUTOUT 3'))\n",
    "imdb_ind_top_100(url3)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('OUTOUT 4'))\n",
    "ind_presi_list(url4)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('OUTOUT 5'))\n",
    "icc_mens_rankings(url51,url52,url53)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('OUTOUT 6'))\n",
    "icc_womens_rankings(url61,url62,url63)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('Output 7'))\n",
    "news_details(url7)\n",
    "print('{:*^100}'.format('OUTOUT 8'))\n",
    "time.sleep(2.0)\n",
    "most_dwn_articles(url8)\n",
    "print('{:*^100}'.format('OUTOUT 9'))\n",
    "dine_out(url9)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('OUTOUT 10'))\n",
    "goog_publ(url10)\n",
    "time.sleep(2.0)\n",
    "print('{:*^100}'.format('ENJOYED SCRAPPING THE WEB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2de638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
