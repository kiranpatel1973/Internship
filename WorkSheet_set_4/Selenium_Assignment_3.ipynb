{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02eb87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import re\n",
    "\n",
    "## ANSWER 1\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')  ## connect to web driver\n",
    "driver.maximize_window() \n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(5)\n",
    "search_text = driver.find_element_by_id(\"twotabsearchtextbox\").send_keys(\"Music KeyBoard\")\n",
    "click_search= driver.find_element_by_id(\"nav-search-submit-button\").click()\n",
    "\n",
    "## ANSWER 1\n",
    "\n",
    "## ANSWER 2\n",
    "\n",
    "name_of_product = driver.find_elements_by_xpath(\"//span[@class='a-size-base-plus a-color-base a-text-normal']\")\n",
    "nop = []           ## NAME OF THE PRODUCT\n",
    "bn  = []           ## BRAND NAME ** ASSUMING FIRST WORD IS BRAND NAME\n",
    "for n in name_of_product:\n",
    "    if n.text is None:\n",
    "        nop.append('-')\n",
    "        bn.append('-')\n",
    "    else:    \n",
    "        nop.append(n.text)\n",
    "        bn.append(n.text.split(' ').pop(0))\n",
    "\n",
    "for x in range(len(nop)):\n",
    "    if len(nop[x]) == 0:\n",
    "        nop[x] = '-'\n",
    "        \n",
    "for y in range(len(bn)):\n",
    "    if len(bn[y]) == 0:\n",
    "        bn[y] = '-'\n",
    "\n",
    "price_of_product = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\") \n",
    "pp = []  ## Prince of the Product \n",
    "re = []  ## Return / Exchange \n",
    "\n",
    "for p in price_of_product:\n",
    "    pp.append(p.text)\n",
    "    re.append('-')\n",
    "\n",
    "for z in range(len(pp)):\n",
    "    if len(pp[z]) == 0:\n",
    "        pp[z] = '-'  \n",
    "del pp[1]        \n",
    "del re[1]\n",
    "\n",
    "expected_delivery = driver.find_elements_by_xpath(\"//span[@class='a-color-base a-text-bold']\")\n",
    "exp_del = []  ## Expected Delivery \n",
    "for g in expected_delivery:\n",
    "    exp_del.append(g.text)\n",
    "    \n",
    "pro_url = driver.find_elements_by_xpath(\"//img[@class='s-image']\") \n",
    "url =[] ## Product URL \n",
    "for k in pro_url:\n",
    "    url.append(k.get_attribute('src'))\n",
    "    \n",
    "if len(nop) == len(bn) == len(pp) == len(re) == len(exp_del) == len(url):\n",
    "    ## create data frame\n",
    "    keyboard_df = pd.DataFrame({'Brand Name':bn,'Name Of Product':nop,'Price':pp,'Return/Exchange':re,'Expected Delivery':exp_del,'Product URL':url})\n",
    "driver.close()\n",
    "\n",
    "## ANSWER 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ca881",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER 3\n",
    "\n",
    "## List Of Image Items to Search in google.com website\n",
    "items_to_search = ['fruits','cars','Machine Learning','Guitar','Cakes']\n",
    "\n",
    "## Loop Thru Images List Item\n",
    "for its in items_to_search:\n",
    "    ## Creating Folder on Local PC to store the images files in jpeg format\n",
    "    if its == 'fruits':\n",
    "        save_folder = 'img1'\n",
    "    elif its == 'cars':\n",
    "        save_folder = 'img2'\n",
    "    elif its == 'Machine Learning':\n",
    "        save_folder = 'img3'\n",
    "    elif its == 'Guitar':\n",
    "        save_folder = 'img4'\n",
    "    elif its == 'Cakes':\n",
    "        save_folder = 'img5'\n",
    "        \n",
    "    ## connect to web driver\n",
    "    driver = webdriver.Chrome('chromedriver.exe')  \n",
    "    driver.maximize_window()\n",
    "    ## Open the URL - URL will be closed and open for each item to search.\n",
    "    driver.get('https://images.google.com/')\n",
    "\n",
    "    ## Code to close the sign-in popup ....this was an tough task.\n",
    "    iframe = driver.find_element_by_xpath(\"//iframe[contains(@name, 'callout')]\")\n",
    "    driver.switch_to.frame(iframe)\n",
    "    no_thanks = driver.find_element_by_xpath(\"//button[@class='M6CB1c rr4y5c']\").click()\n",
    "    driver.switch_to.default_content()  \n",
    "    ## Code to close the sign-in popup ....this was an tough task.\n",
    "    \n",
    "    cnt = 0\n",
    "    search_images = driver.find_element_by_xpath(\"//input[@name='q']\").send_keys(its)\n",
    "    time.sleep(5)\n",
    "    search_click  = driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\").click()\n",
    "    \n",
    "    images_url = driver.find_elements_by_xpath(\"//div[@class='bRMDJf islir']/img\")\n",
    "    \n",
    "    ## Create the folder using OS commands.\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "        \n",
    "    ## Extracting the URL using enumerate and urlretrieve commands - urllib package used.\n",
    "    for x,y in enumerate(images_url):\n",
    "        if y.get_attribute('src') != 'None':\n",
    "            images_url = y.get_attribute('src')\n",
    "            images_url = str(images_url)\n",
    "            urllib.request.urlretrieve(images_url,os.path.join(save_folder,its+'-'+str(x)+'.jpeg'))\n",
    "            cnt = cnt + 1\n",
    "            if cnt == 10:\n",
    "                break\n",
    "    driver.close()\n",
    "\n",
    "## ANSWER 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER 4\n",
    "driver = webdriver.Chrome('chromedriver.exe')  ## connect to web driver\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(5)  ## delay for the website to get open.\n",
    "##close popup \n",
    "popclo = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "\n",
    "search_text = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_text.send_keys(\"Oneplus Nord\")\n",
    "\n",
    "search_button = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "## Scraping the details\n",
    "\n",
    "title_details = driver.find_elements_by_xpath(\"//div[@class='_4rR01T']\")\n",
    "\n",
    "brand = []\n",
    "phone = []\n",
    "colour= []\n",
    "for det in title_details:\n",
    "    brand.append(det.text.split(' ').pop(0))\n",
    "    phone.append(det.text.split('(').pop(0))\n",
    "    colour.append(det.text.split('(').pop(1).split(',').pop(0))\n",
    "\n",
    "ram =[]\n",
    "rom =[]\n",
    "ramrom_details = driver.find_elements_by_xpath(\"//div[@class='fMghEO']/ul/li[1]\")\n",
    "for raro in ramrom_details:\n",
    "    ram.append(raro.text.split('|').pop(0))\n",
    "    rom.append(raro.text.split('|').pop(1))\n",
    "\n",
    "disp =[]\n",
    "disp_details = driver.find_elements_by_xpath(\"//div[@class='fMghEO']/ul/li[2]\")\n",
    "for dis in disp_details:\n",
    "    disp.append(dis.text)\n",
    "\n",
    "pri = []\n",
    "sec = []\n",
    "cam_details = driver.find_elements_by_xpath(\"//div[@class='fMghEO']/ul/li[3]\")\n",
    "for camdet in cam_details:\n",
    "    if re.findall(\"\\|\",camdet.text):\n",
    "        pri.append(camdet.text.split('|').pop(0))\n",
    "        sec.append(camdet.text.split('|').pop(1))\n",
    "    else:\n",
    "        pri.append(camdet.text)\n",
    "        sec.append('-')\n",
    "\n",
    "batcap = []\n",
    "batcap_details = driver.find_elements_by_xpath(\"//div[@class='fMghEO']/ul/li[4]\")\n",
    "for baca in batcap_details:\n",
    "    batcap.append(baca.text)\n",
    "\n",
    "prc = []\n",
    "price_details = driver.find_elements_by_xpath(\"//div[@class='_30jeq3 _1_WHN1']\")\n",
    "for pr in price_details:\n",
    "    prc.append(pr.text)\n",
    "    \n",
    "pro_url = []\n",
    "prourl_details = driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")\n",
    "for prourl in prourl_details:\n",
    "    pro_url.append(prourl.get_attribute('href'))\n",
    "\n",
    "if len(brand) == len(phone) == len(colour) == len(ram) == len(rom) == len(pri) == len(sec) == len(disp) == len(batcap) == len(prc) == len(pro_url):\n",
    "    phone_df = pd.DataFrame({'Brand Name':brand,'Smartphone Name':phone,'Colour':colour,'RAM':ram,'Storage-ROM':rom,\n",
    "                             'Primary Camera':pri,'Secondary Camera':sec,'Display Size':disp,'Battery Capacity':batcap,\n",
    "                             'Price':prc,'Product URL':pro_url})\n",
    "\n",
    "folder_name = 'phone_data'\n",
    "if not os.path.exists(folder_name): \n",
    "    os.mkdir(folder_name)\n",
    "    phone_df.to_csv(folder_name+'\\data.csv')\n",
    "    \n",
    "driver.close()\n",
    "## ANSWER 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76876027",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER 5\n",
    "\n",
    "## connect to web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')  \n",
    "driver.maximize_window()\n",
    "\n",
    "## Open the URL - URL will be closed and open for each item to search.\n",
    "driver.get('https://www.google.com/maps/@20.9485824,72.9284608,14z')\n",
    "search_city = driver.find_element_by_id(\"searchboxinput\")\n",
    "search_city.send_keys('Mumbai')\n",
    "search_click = driver.find_element_by_id(\"searchbox-searchbutton\")\n",
    "search_click.click()\n",
    "time.sleep(5)\n",
    "\n",
    "cur_url = driver.current_url ## get the current url where the geo location details exists.\n",
    "\n",
    "## Extract Latitude and Longitude from the URL using Regular Expression\n",
    "x = re.split('@',cur_url)\n",
    "y = x[1]\n",
    "z = re.split(',',y)\n",
    "latitude = z[0]\n",
    "longitude =z[1] \n",
    "\n",
    "print('LATITUDE  => ' + latitude)\n",
    "print('LONGITUDE => ' + longitude)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "## ANSWER 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER 6\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')  ## connect to web driver\n",
    "driver.maximize_window()\n",
    "driver.get('https://trak.in/india-startup-funding-investment-2015/')\n",
    "h2tags = driver.find_elements_by_tag_name('h2')\n",
    "jan_dat = []\n",
    "jan_nam = []\n",
    "jan_city =[]\n",
    "jan_amt =[]\n",
    "\n",
    "feb_dat = []\n",
    "feb_nam = []\n",
    "feb_city =[]\n",
    "feb_amt =[]\n",
    "\n",
    "mar_dat = []\n",
    "mar_nam = []\n",
    "mar_city =[]\n",
    "mar_amt =[]\n",
    "\n",
    "for x in h2tags:\n",
    "    if x.text == 'January, 2021':\n",
    "        jan_det1 = driver.find_elements_by_xpath(\"//table[@id='tablepress-54']/tbody/tr/td[2]\") ## date\n",
    "        jan_det2 = driver.find_elements_by_xpath(\"//table[@id='tablepress-54']/tbody/tr/td[3]\") ## Starup Name\n",
    "        jan_det3 = driver.find_elements_by_xpath(\"//table[@id='tablepress-54']/tbody/tr/td[6]\") ## City\n",
    "        jan_det4 = driver.find_elements_by_xpath(\"//table[@id='tablepress-54']/tbody/tr/td[9]\") ## Amount\n",
    "        \n",
    "        for jd1 in jan_det1:\n",
    "            jan_dat.append(jd1.text)\n",
    "            \n",
    "        for jd2 in jan_det2:\n",
    "            jan_nam.append(jd2.text)\n",
    "        \n",
    "        for jd3 in jan_det3:\n",
    "            jan_city.append(jd3.text)\n",
    "            \n",
    "        for jd4 in jan_det4:\n",
    "            jan_amt.append(jd4.text)    \n",
    "    \n",
    "    elif x.text == 'February, 2021':\n",
    "        feb_det1 = driver.find_elements_by_xpath(\"//table[@id='tablepress-55']/tbody/tr/td[2]\") ## date\n",
    "        feb_det2 = driver.find_elements_by_xpath(\"//table[@id='tablepress-55']/tbody/tr/td[3]\") ## Starup Name\n",
    "        feb_det3 = driver.find_elements_by_xpath(\"//table[@id='tablepress-55']/tbody/tr/td[6]\") ## City\n",
    "        feb_det4 = driver.find_elements_by_xpath(\"//table[@id='tablepress-55']/tbody/tr/td[9]\") ## Amount\n",
    "        \n",
    "        for fd1 in feb_det1:\n",
    "            feb_dat.append(fd1.text)\n",
    "            \n",
    "        for fd2 in feb_det2:\n",
    "            feb_nam.append(fd2.text)\n",
    "        \n",
    "        for fd3 in feb_det3:\n",
    "            feb_city.append(fd3.text)\n",
    "            \n",
    "        for fd4 in feb_det4:\n",
    "            feb_amt.append(fd4.text)    \n",
    "    elif x.text == 'March, 2021':\n",
    "        mar_det1 = driver.find_elements_by_xpath(\"//table[@id='tablepress-56']/tbody/tr/td[2]\") ## date\n",
    "        mar_det2 = driver.find_elements_by_xpath(\"//table[@id='tablepress-56']/tbody/tr/td[3]\") ## Starup Name\n",
    "        mar_det3 = driver.find_elements_by_xpath(\"//table[@id='tablepress-56']/tbody/tr/td[6]\") ## City\n",
    "        mar_det4 = driver.find_elements_by_xpath(\"//table[@id='tablepress-56']/tbody/tr/td[9]\") ## Amount\n",
    "        \n",
    "        for md1 in mar_det1:\n",
    "            mar_dat.append(md1.text)\n",
    "            \n",
    "        for md2 in mar_det2:\n",
    "            mar_nam.append(md2.text)\n",
    "        \n",
    "        for md3 in mar_det3:\n",
    "            mar_city.append(md3.text)\n",
    "            \n",
    "        for md4 in mar_det4:\n",
    "            mar_amt.append(md4.text)\n",
    "\n",
    "jan_fund_df = pd.DataFrame({'Date':jan_dat,'StartUp Name':jan_nam,'City':jan_city,'Amount':jan_amt})\n",
    "feb_fund_df = pd.DataFrame({'Date':feb_dat,'StartUp Name':feb_nam,'City':feb_city,'Amount':feb_amt})\n",
    "mar_fund_df = pd.DataFrame({'Date':mar_dat,'StartUp Name':mar_nam,'City':mar_city,'Amount':mar_amt})\n",
    "\n",
    "\n",
    "driver.close()\n",
    "\n",
    "## ANSWER 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER 7\n",
    "driver = webdriver.Chrome('chromedriver.exe')  ## connect to web driver\n",
    "driver.maximize_window()\n",
    "driver.get('https://digit.in/')\n",
    "gaming_select = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[4]/ul/li[7]/a\").click()\n",
    "\n",
    "recent_post = driver.find_elements_by_xpath(\"//div[@class='post']/div/div\")\n",
    "re_post = []\n",
    "for po in recent_post:\n",
    "    if po.text != 'None':\n",
    "        re_post.append(po.text.replace('\\n',\"\"))\n",
    "\n",
    "v_link = []        \n",
    "video_links = driver.find_elements_by_xpath(\"//div[@class='Thumb-new']/a\")\n",
    "for vl in video_links:\n",
    "    v_link.append(vl.get_attribute('href'))\n",
    "\n",
    "news = []\n",
    "news_det = driver.find_elements_by_xpath(\"//div[@class='product-text']\")\n",
    "for x in news_det:\n",
    "    news.append(x.text.replace('\\n',\"\"))\n",
    "    \n",
    "driver.close()\n",
    "## ANSWER 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER8\n",
    "driver = webdriver.Chrome('chromedriver.exe') \n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.forbes.com/')\n",
    "but1 = driver.find_element_by_xpath(\"//button[@class='icon--hamburger']\").click()\n",
    "time.sleep(20)\n",
    "bill = driver.find_element_by_xpath(\"//li[@data-position='1']\");\n",
    "action = ActionChains(driver)\n",
    "action.move_to_element(bill).perform()\n",
    "time.sleep(5)\n",
    "all_bill = driver.find_element_by_link_text(\"World's Billionaires\").click()\n",
    "time.sleep(20)\n",
    "\n",
    "## Scrape Data\n",
    "rank =[]\n",
    "name =[]\n",
    "networth=[]\n",
    "age =[]\n",
    "citzen =[]\n",
    "src =[]\n",
    "indtry =[]\n",
    "\n",
    "\n",
    "r_det = driver.find_elements_by_xpath(\"//div[@class='rank']\")\n",
    "for q in r_det:\n",
    "    rank.append(q.text)\n",
    "\n",
    "p_det = driver.find_elements_by_xpath(\"//div[@class='personName']\")\n",
    "for w in p_det:\n",
    "    name.append(w.text)\n",
    "\n",
    "n_det = driver.find_elements_by_xpath(\"//div[@class='netWorth']\")\n",
    "for e in n_det:\n",
    "    networth.append(e.text)\n",
    "\n",
    "a_det = driver.find_elements_by_xpath(\"//div[@class='age']\")\n",
    "for r in a_det:\n",
    "    age.append(r.text)\n",
    "\n",
    "c_det = driver.find_elements_by_xpath(\"//div[@class='countryOfCitizenship']\")\n",
    "for t in c_det:\n",
    "    citzen.append(t.text)\n",
    "\n",
    "s_det = driver.find_elements_by_xpath(\"//span[@class='source-text']\")\n",
    "for y in s_det:\n",
    "    src.append(y.text)\n",
    "\n",
    "i_det = driver.find_elements_by_xpath(\"//div[@class='category']\")\n",
    "for u in i_det:\n",
    "    indtry.append(u.text)\n",
    "    \n",
    "world_bill_df = pd.DataFrame({'Rank':rank,'Name':name,'Net Worth':networth,'Age':age,'Citizen':citzen,'Source':src,'Industry':indtry})\n",
    "print(world_bill_df)\n",
    "driver.close()\n",
    "## ANSWER8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b72935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
