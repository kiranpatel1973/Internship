{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9cbc7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Brand Name                                  Brand Description Price\n",
      "0    VINCENT CHASE          UV Protection Rectangular Sunglasses (52)  ₹649\n",
      "1    VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...  ₹749\n",
      "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799\n",
      "3        Elligator                UV Protection Round Sunglasses (54)  ₹295\n",
      "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639\n",
      "..             ...                                                ...   ...\n",
      "95  ROZZETTA CRAFT     UV Protection Spectacle Sunglasses (Free Size)  ₹379\n",
      "96          PIRASO              UV Protection Aviator Sunglasses (54)  ₹246\n",
      "97          PIRASO             UV Protection Wayfarer Sunglasses (32)  ₹202\n",
      "98              Mi           Polarized Aviator Sunglasses (Free Size)  ₹839\n",
      "99       ROYAL SON  Polarized, UV Protection Wayfarer, Retro Squar...  ₹664\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "   Rating       Review Summary  \\\n",
      "0       5       Simply awesome   \n",
      "1       5  Best in the market!   \n",
      "2       5     Perfect product!   \n",
      "3       5   Highly recommended   \n",
      "4       5    Worth every penny   \n",
      "..    ...                  ...   \n",
      "95      5            Fabulous!   \n",
      "96      5        Great product   \n",
      "97      5    Worth every penny   \n",
      "98      4          Good choice   \n",
      "99      5   Highly recommended   \n",
      "\n",
      "                                          Full Review  \n",
      "0   Really satisfied with the Product I received.....  \n",
      "1   Great iPhone very snappy experience as apple k...  \n",
      "2   Amazing phone with great cameras and better ba...  \n",
      "3   What a camera .....just awesome ..you can feel...  \n",
      "4   Previously I was using one plus 3t it was a gr...  \n",
      "..                                                ...  \n",
      "95  This is my first iOS phone. I am very happy wi...  \n",
      "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
      "97  i11 is worthy to buy, too much happy with the ...  \n",
      "98  So far it’s been an AMAZING experience coming ...  \n",
      "99  iphone 11 is a very good phone to buy only if ...  \n",
      "\n",
      "[100 rows x 3 columns]\n",
      "             Brand                                Product Description   Price\n",
      "0           BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹499\n",
      "1            GUSTO                                   Sneakers For Men    ₹339\n",
      "2           BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men    ₹269\n",
      "3         Magnolia                                   Sneakers For Men    ₹374\n",
      "4         URBANBOX                          Sneakers Sneakers For Men    ₹198\n",
      "5            BIRDE  Stylish Comfortable Lightweight, Breathable Ca...    ₹299\n",
      "6           Labbin                                   Sneakers For Men    ₹499\n",
      "7         RapidBox                                   Sneakers For Men    ₹695\n",
      "8           Layasa                                   Sneakers For Men    ₹399\n",
      "9         Magnolia                                   Sneakers For Men    ₹374\n",
      "10       EZDEZARIO  Shoes in Black Color Party wear/Outdoor/Casual...    ₹399\n",
      "11       EZDEZARIO  Casual Sneakers Shoes For Men Sneakers For Men...    ₹399\n",
      "12          BRUTON                           Sneaker Sneakers For Men    ₹269\n",
      "13        HOTSTYLE                                   Sneakers For Men    ₹258\n",
      "14            aadi                                   Sneakers For Men    ₹399\n",
      "15       EZDEZARIO  Fashion Outdoor Canvas Casual Light Weight Lac...    ₹449\n",
      "16            aadi                                   Sneakers For Men    ₹319\n",
      "17          BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men    ₹299\n",
      "18          BRUTON  Combo Pack Of 2 Latest Stylish Casual Shoes fo...    ₹499\n",
      "19        sixXplus  Sneakers For Men (Black) Casual For Men Sneake...    ₹521\n",
      "20      D-SNEAKERZ  Casual , Partywear Sneakers Shoes For Men's An...    ₹284\n",
      "21           BIRDE  Stylish Comfortable Lightweight, Breathable Wa...    ₹299\n",
      "22         Airland  1259 smart black lace-ups sneakers for men Sne...    ₹210\n",
      "23      HIGHLANDER                                   Sneakers For Men    ₹895\n",
      "24          Rzisbo                                   Sneakers For Men    ₹490\n",
      "25           CLYMB                                   Sneakers For Men    ₹519\n",
      "26          Kzaara                                   Sneakers For Men    ₹254\n",
      "27          Kraasa                              Boom Sneakers For Men    ₹611\n",
      "28          BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹188\n",
      "29          corsac        STYLISH MENS BLACK SNEAKER Sneakers For Men    ₹499\n",
      "30        KWIK FIT  Kwik FIT casual sneaker shoes and partywear sh...    ₹397\n",
      "31            PUMA               Smash Vulc v3 Lo CV Sneakers For Men  ₹1,999\n",
      "32         Airland                              shoe Sneakers For Men    ₹207\n",
      "33         Numenzo                        411 Casual Sneakers For Men    ₹474\n",
      "34           BIRDE              Sports Running Shoes Sneakers For Men    ₹249\n",
      "35        LE GREEM  Comfortable & Ultra Light Weight Sneaker Sneak...    ₹449\n",
      "36            PUMA             Puma Rebound LayUp SL Sneakers For Men  ₹2,934\n",
      "37        ASTEROID  Original Luxury Branded Fashionable Men's Casu...    ₹499\n",
      "38    Robbie jones                                   Sneakers For Men    ₹499\n",
      "39  KNIGHT WALKERS                                   Sneakers For Men    ₹648\n",
      "Cant Open Web Site\n",
      "                                               Title             Ratings  \\\n",
      "0  Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...  4.5 out of 5 stars   \n",
      "1  Lenovo Yoga 9 11th Gen Intel Core i7 14\" 4K Ul...  3.9 out of 5 stars   \n",
      "2  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  3.8 out of 5 stars   \n",
      "3  Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...  4.2 out of 5 stars   \n",
      "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5 stars   \n",
      "5  LG Gram 16 Intel Evo 11th Gen i7 Thin & Light ...  4.4 out of 5 stars   \n",
      "6  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...  3.2 out of 5 stars   \n",
      "7  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  4.5 out of 5 stars   \n",
      "8  LG Gram 17 Intel Evo 11th Gen i7 Thin & Light ...  4.1 out of 5 stars   \n",
      "9  Lenovo IdeaPad 5 Pro 11th Gen Intel Core i7 14...  3.6 out of 5 stars   \n",
      "\n",
      "      Price  \n",
      "0    73,400  \n",
      "1  1,68,990  \n",
      "2    84,990  \n",
      "3    87,809  \n",
      "4    86,990  \n",
      "5    84,999  \n",
      "6  1,16,990  \n",
      "7    79,990  \n",
      "8    88,490  \n",
      "9    75,104  \n",
      "        Company Name          Tot.Sal.Rec. Avg.Sal. Min.Sal.  Max.Sal  \\\n",
      "0            Walmart  based on 12 salaries  ₹ 30.6L  ₹ 25.0L  ₹ 36.0L   \n",
      "1           Ab Inbev  based on 33 salaries  ₹ 20.8L  ₹ 15.0L  ₹ 26.2L   \n",
      "2                 ZS  based on 15 salaries  ₹ 16.7L  ₹ 11.0L  ₹ 22.0L   \n",
      "3              Optum  based on 32 salaries  ₹ 15.9L  ₹ 11.0L  ₹ 22.5L   \n",
      "4       Reliance Jio  based on 21 salaries  ₹ 15.7L   ₹ 5.6L  ₹ 26.2L   \n",
      "5  Fractal Analytics  based on 89 salaries  ₹ 15.5L  ₹ 10.0L  ₹ 23.0L   \n",
      "6    Tiger Analytics  based on 51 salaries  ₹ 14.8L   ₹ 9.0L  ₹ 20.0L   \n",
      "7       UnitedHealth  based on 57 salaries  ₹ 14.0L   ₹ 8.3L  ₹ 21.1L   \n",
      "8        EXL Service  based on 21 salaries  ₹ 13.2L   ₹ 7.6L  ₹ 21.0L   \n",
      "9           Deloitte  based on 69 salaries  ₹ 12.8L   ₹ 7.0L  ₹ 25.0L   \n",
      "\n",
      "      Exp.Req.  \n",
      "0    3 yrs exp  \n",
      "1  3-4 yrs exp  \n",
      "2    2 yrs exp  \n",
      "3  3-4 yrs exp  \n",
      "4  3-4 yrs exp  \n",
      "5  2-4 yrs exp  \n",
      "6  2-4 yrs exp  \n",
      "7  2-4 yrs exp  \n",
      "8  3-4 yrs exp  \n",
      "9  2-4 yrs exp  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                 ## to create data frame\n",
    "import selenium                     ## libraries to work with selenium\n",
    "from selenium import webdriver      ## to open automated chrome browser\n",
    "import warnings                     ## to ignore any sort of warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time                         ## use to stop execution of program for few seconds.\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "## QUESTION 1\n",
    "''''\n",
    "driver = webdriver.Chrome('chromedriver.exe')  ## connect to web driver\n",
    "driver.maximize_window() \n",
    "driver.get('https://www.naukri.com/')\n",
    "time.sleep(2) \n",
    "\n",
    "## Enter Skill / Designation / Companies\n",
    "search_para1_skills = driver.find_element_by_xpath(\"//input[@placeholder='Enter skills / designations / companies']\").send_keys('Data Analyst')\n",
    "## Enter Location\n",
    "search_para2_locati = driver.find_element_by_xpath(\"//input[@placeholder='Enter location']\").send_keys('Banglore')\n",
    "search_button = driver.find_element_by_xpath(\"//div[@class='qsbSubmit']\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "## Scrapping the html elements and storing in list.\n",
    "job_title = []\n",
    "job_loc = []\n",
    "comp_name = []\n",
    "req_exp = []\n",
    "\n",
    "job_title_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')  ## Scrapping Job Titles\n",
    "job_title_tags[0:10]        ## use range to print top 10 results\n",
    "\n",
    "for x in job_title_tags:\n",
    "    ti = x.text\n",
    "    job_title.append(ti)\n",
    "\n",
    "job_loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\") ## Scrapping Job Location\n",
    "job_loc_tags[0:10]\n",
    "\n",
    "for y in job_loc_tags:\n",
    "    lo = y.text\n",
    "    job_loc.append(lo)\n",
    "    \n",
    "comp_name_tags = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")  ## Scrapping Company Name\n",
    "comp_name_tags[0:10]\n",
    "\n",
    "for z in comp_name_tags:\n",
    "    co = z.text\n",
    "    comp_name.append(co)\n",
    "\n",
    "req_exp_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")  ## Scrapping Required Experience   \n",
    "req_exp_tags[0:10]\n",
    "\n",
    "for e in req_exp_tags:\n",
    "    ex = e.text\n",
    "    req_exp.append(ex)\n",
    "\n",
    "driver.close()    ## Close Automated Browser.\n",
    "\n",
    "## Data Frame \n",
    "naukri_df1 = pd.DataFrame({'Job Title':job_title,'Job Location':job_loc,'Company Name':comp_name,'Required Experience':req_exp})\n",
    "## print(naukri_df1)\n",
    "\n",
    "\n",
    "## QUESTION 2\n",
    "\n",
    "driver1 = webdriver.Chrome('chromedriver.exe')  ## connect to web driver\n",
    "driver.maximize_window() \n",
    "driver1.get('https://www.naukri.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "## Enter Skill / Designation / Companies\n",
    "search_para1_skills = driver1.find_element_by_xpath(\"//input[@placeholder='Enter skills / designations / companies']\").send_keys('Data Scients')\n",
    "## Enter Location\n",
    "search_para2_locati = driver1.find_element_by_xpath(\"//input[@placeholder='Enter location']\").send_keys('Banglore')\n",
    "search_button = driver1.find_element_by_xpath(\"//div[@class='qsbSubmit']\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "## Scrapping the html elements and storing in list.\n",
    "job_title1 = []\n",
    "job_loc1 = []\n",
    "comp_name1 = []\n",
    "\n",
    "job_title_tags1 = driver1.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')  ## Scrapping Job Titles\n",
    "job_title_tags1[0:10]        ## use range to print top 10 results\n",
    "\n",
    "for x in job_title_tags1:\n",
    "    ti = x.text\n",
    "    job_title1.append(ti)\n",
    "\n",
    "job_loc_tags1 = driver1.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\") ## Scrapping Job Location\n",
    "job_loc_tags1[0:10]\n",
    "\n",
    "for y in job_loc_tags1:\n",
    "    lo = y.text\n",
    "    job_loc1.append(lo)\n",
    "    \n",
    "comp_name_tags1 = driver1.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")  ## Scrapping Company Name\n",
    "comp_name_tags1[0:10]\n",
    "\n",
    "for z in comp_name_tags1:\n",
    "    co = z.text\n",
    "    comp_name1.append(co)\n",
    "\n",
    "driver1.close()    ## Close Automated Browser.\n",
    "\n",
    "## Data Frame \n",
    "naukri_df2 = pd.DataFrame({'Job Title':job_title1,'Job Location':job_loc1,'Company Name':comp_name1})\n",
    "##print(naukri_df2)\n",
    "\n",
    "## QUESTION 3\n",
    "\n",
    "driver2 = webdriver.Chrome('chromedriver.exe')\n",
    "driver2.maximize_window() \n",
    "driver2.get('https://www.naukri.com/')\n",
    "time.sleep(2)\n",
    "## Enter Skill / Designation / Companies\n",
    "search_para1_skills = driver2.find_element_by_class_name('suggestor-input')   \n",
    "search_para1_skills.send_keys('Data Scientist')\n",
    "search_button = driver2.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "## loc_fil = driver2.find_element_by_xpath('//*[@id=\"chk-Delhi / NCR-cityTypeGid-\"]').click()  Not Working \n",
    "## sal_fil = driver2.find_element_by_xpath('//input[@id=\"chk-3-6 Lakhs-ctcFilter-\"]').click()  Not Working\n",
    "## ElementNotInteractableException even though element is identified as checkbox\n",
    "job_list =[]\n",
    "j_tit_tg = driver2.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')  ## Scrapping Job Titles\n",
    "j_tit_tg[0:10]\n",
    "for k in j_tit_tg:\n",
    "    job = k.text\n",
    "    job_list.append(job)\n",
    "\n",
    "## Data Frame \n",
    "naukri_df3 = pd.DataFrame({'Job Title':job_list})\n",
    "print(naukri_df3)\n",
    "driver2.close()    ## Close Automated Browser.\n",
    "'''\n",
    "\n",
    "## QUESTION 4\n",
    "\n",
    "driver3 = webdriver.Chrome('chromedriver.exe')\n",
    "driver3.get('https://www.flipkart.com/')\n",
    "## Close Login Pop Up Window\n",
    "driver3.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "time.sleep(2)\n",
    "search_para = driver3.find_element_by_class_name('_3704LK')\n",
    "search_para.send_keys('sunglasses')\n",
    "search_but = driver3.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "time.sleep(2)\n",
    "b_name = []\n",
    "b_desc = []\n",
    "b_price =[]\n",
    "for pg in range(0,3):\n",
    "    brand_name = driver3.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for x in brand_name:\n",
    "        b_name.append(x.text)\n",
    "\n",
    "    brand_desc = driver3.find_elements_by_xpath(\"//a[@class='IRpwTa']\")    \n",
    "    for y in brand_desc:\n",
    "        b_desc.append(y.text)\n",
    "\n",
    "    brand_price = driver3.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for z in brand_price:\n",
    "        b_price.append(z.text)\n",
    "next_but = driver3.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_but.click()\n",
    "time.sleep(5)\n",
    "\n",
    "## remove last 20 entries from each list\n",
    "if len(b_name) == 120:\n",
    "    del b_name[-20:]\n",
    "if len(b_desc) == 120:\n",
    "    del b_desc[-20:]\n",
    "if len(b_price) == 120:\n",
    "    del b_price[-20:]\n",
    "\n",
    "if len(b_name) == len(b_desc) == len(b_price):\n",
    "    flip_df = pd.DataFrame({'Brand Name':b_name,'Brand Description':b_desc,'Price':b_price})\n",
    "\n",
    "print(flip_df)    \n",
    "driver3.close()\n",
    "\n",
    "\n",
    "## QUESTION 5\n",
    "\n",
    "try:\n",
    "    driver = webdriver.Chrome('chromedriver.exe')                           ## connect to web driver\n",
    "    driver.maximize_window()                                                ## maximize the window\n",
    "    ## open the url\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    ## Close Login Pop Up Window\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    time.sleep(2)                                                            ## wait for 2 seconds \n",
    "    search_para1 = driver.find_element_by_class_name('_3704LK').send_keys('iphone 11')\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "    time.sleep(2)  \n",
    "    sele_pro = driver.find_elements_by_xpath(\"//div[@class='_2kHMtA']/a\")\n",
    "    for x in sele_pro:\n",
    "        lk = x.get_attribute('href')\n",
    "        driver.get(lk)\n",
    "        time.sleep(2) \n",
    "        break\n",
    "    ## click all reviews so that 100 reviews are displayed\n",
    "    all_rev = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()\n",
    "    time.sleep(2) \n",
    "    \n",
    "    ## scrape the data\n",
    "    rating = []\n",
    "    rev_summ = []\n",
    "    full_rev = []\n",
    "    \n",
    "    for rev in range(0,10):\n",
    "        l_rat = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for x in l_rat:\n",
    "            rating.append(x.text)\n",
    "\n",
    "        l_rev_summ = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for y in l_rev_summ:\n",
    "            rev_summ.append(y.text)\n",
    "\n",
    "        l_full_rev = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for z in l_full_rev:\n",
    "            full_rev.append(z.text)\n",
    "            \n",
    "    next_but = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]/span\").click()\n",
    "    time.sleep(2) \n",
    "    \n",
    "    if len(rating) == len(rev_summ) == len(full_rev) == 100:\n",
    "        flipcart_df = pd.DataFrame({'Rating':rating,'Review Summary':rev_summ,'Full Review':full_rev})\n",
    "        \n",
    "    print(flipcart_df)\n",
    "    driver.close() \n",
    "    \n",
    "except WebDriverException:    \n",
    "    print('Cant Open Web Site')\n",
    "    driver.close()                                                           ## close web page  \n",
    "\n",
    "\n",
    "#### QUESTION 6\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')                           ## connect to web driver\n",
    "driver.maximize_window()                                                ## maximize the window\n",
    "try:\n",
    "    ## open the url\n",
    "    driver.get('https://www.flipkart.com')                                    \n",
    "    ## Close Login Pop Up Window\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    time.sleep(2)                                                            ## wait for 2 seconds \n",
    "    ## Search for Sneakers\n",
    "    search = driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sneakers')\n",
    "    search_conf = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    ## Scrap the Data \n",
    "    brand =[]\n",
    "    pro_desc =[]\n",
    "    price =[]\n",
    "    \n",
    "    b_name = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for x in b_name:\n",
    "        brand.append(x.text)\n",
    "        \n",
    "    p_desc = driver.find_elements_by_class_name(\"IRpwTa\")\n",
    "    for y in p_desc:\n",
    "        pro_desc.append(y.text)\n",
    "        \n",
    "    p_price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")    \n",
    "    for z in p_price:\n",
    "        price.append(z.text)\n",
    "   \n",
    "    if len(brand) == len(pro_desc) == len(price):\n",
    "        flip_df = pd.DataFrame({'Brand':brand,'Product Description':pro_desc,'Price':price})\n",
    "        print(flip_df)\n",
    "    \n",
    "    driver.close()   \n",
    "    \n",
    "except WebDriverException:    \n",
    "    print('Cant Open Web Site')\n",
    "    driver.close()                                                           ## close web page  \n",
    "\n",
    "### QUESTION 7\n",
    "\n",
    "driver = webdriver.Chrome('C:\\web driver\\chromedriver.exe')             ## connect to web driver\n",
    "driver.maximize_window()                                                ## maximize the window\n",
    "try:\n",
    "    driver.get('https://www.myntra.com/shoes')                                    ## open the url\n",
    "    time.sleep(2)                                                                 ## wait for 2 seconds \n",
    "except WebDriverException:    \n",
    "    print('Cant Open Web Site')\n",
    "    driver.close()                                                           ## close web page  \n",
    "\n",
    "\n",
    "### QUESTION 8\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')                           ## connect to web driver\n",
    "driver.maximize_window()                                                ## maximize the window\n",
    "driver.get('https://www.amazon.in/')                                    ## open the url\n",
    "time.sleep(2)                                                           ## wait for 2 seconds \n",
    "\n",
    "## Enter Laptop in the search box\n",
    "ser_box = driver.find_element_by_id(\"twotabsearchtextbox\").send_keys('Laptop')  \n",
    "## Click on the Search Button\n",
    "ser_but = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\").click()\n",
    "## Wait 2 secs for the search results\n",
    "time.sleep(2) \n",
    "## Select Intel I7 Process Check-Box\n",
    "i7_clk = driver.find_element_by_xpath(\"//li[@id='p_n_feature_thirteen_browse-bin/12598163031']/child::span/child::a/child::div\").click()\n",
    "## Wait 2 secs for the search results\n",
    "time.sleep(2) \n",
    "## Scrape the data \n",
    "title = []\n",
    "ratings =[]\n",
    "price =[]\n",
    "## Scrape Title\n",
    "l_laptop = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "## Scrape Price\n",
    "p_laptop = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "## Scrape Ratings\n",
    "r_laptop = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "\n",
    "for x in l_laptop:\n",
    "    title.append(x.text)\n",
    "    if len(title) > 10:\n",
    "        title = title[0:10]        ## Pull top 10 results\n",
    "for y in r_laptop:\n",
    "    ratings.append(y.get_attribute(\"innerHTML\"))\n",
    "    if len(ratings) > 10:\n",
    "        ratings = ratings[0:10]   ## Pull top 10 results\n",
    "for z in p_laptop:\n",
    "    price.append(z.text)\n",
    "    if len(price) > 10:\n",
    "        price = price[0:10]      ## Pull top 10 results\n",
    "        \n",
    "ama_df = pd.DataFrame({'Title':title,'Ratings':ratings,'Price':price})   ## create data frame       \n",
    "print(ama_df)                                                            ## print data frame\n",
    "driver.close()                                                           ## close web page  \n",
    "\n",
    "########  QUESTION 9\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')                           ## connect to web driver\n",
    "driver.maximize_window()                                                ## maximize the window\n",
    "driver.get('https://www.ambitionbox.com/')                              ## open the url\n",
    "time.sleep(2)                                                           ## wait for 2 seconds \n",
    "jobs = driver.find_element_by_partial_link_text(\"Jobs\").click()         ## Click on the Jobs Option\n",
    "fil = driver.find_element_by_xpath(\"//input[@title='Enter Designation, Company or a Skill']\").send_keys('Data Scientist') ## Search For the Job Profile Data Scientist\n",
    "but = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span\").click()\n",
    "time.sleep(2)   ## wait for 2 seconds \n",
    "loc = driver.find_element_by_xpath(\"//div[@title='Location']/i\").click()\n",
    "time.sleep(2)\n",
    "sea_loc = driver.find_element_by_xpath(\"//input[@placeholder='Search locations']\").send_keys('Noida')\n",
    "time.sleep(2)\n",
    "rad = driver.find_element_by_xpath(\"//input[@id='location_Noida']\").click()\n",
    "time.sleep(2)\n",
    "c_nam = []\n",
    "cmp_nam = driver.find_elements_by_xpath(\"//div[@class='company-info']/p\")\n",
    "for l in cmp_nam:\n",
    "    c_nam.append(l.text)\n",
    "t_pos = []\n",
    "tim_pos = driver.find_elements_by_xpath(\"//span[@class='body-small-l'][1]\")\n",
    "for m in tim_pos:\n",
    "    t_pos.append(m.text)\n",
    "c_rat = []    \n",
    "cmp_rat = driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "for n in cmp_rat:\n",
    "    c_rat.append(n.text)\n",
    "if len(c_nam) == len(t_pos) == len(c_rat):\n",
    "    noida_df = pd.DataFrame({'Company Name':c_nam,'Job Posted':t_pos,'Company Ratings':c_rat})\n",
    "    print(noida_df)\n",
    "driver.close()    \n",
    "\n",
    "######### QUESTION 10\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')                           ## connect to web driver\n",
    "driver.maximize_window()                                                ## maximize the window\n",
    "driver.get('https://www.ambitionbox.com/')                              ## open the url\n",
    "time.sleep(2)                                                           ## wait for 2 seconds \n",
    "sal = driver.find_element_by_partial_link_text(\"Salaries\").click()      ## Click on the Salaries Option\n",
    "fil = driver.find_element_by_id(\"jobProfileSearchbox\").send_keys('Data Scientist') ## Search For the Job Profile Data Scientist\n",
    "time.sleep(2)                                                           ## wait for 2 seconds \n",
    "## Click on Data Scientist Pop List. \n",
    "dd = driver.find_element_by_xpath('//*[@id=\"salaries\"]/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p').click()\n",
    "time.sleep(2)                                                           ## wait for 2 seconds \n",
    "## Start Scrapping Data \n",
    "c_name = []\n",
    "s_rec  = []\n",
    "cmp_name = driver.find_elements_by_xpath(\"//div[@class='name']\")       ## Company Name Plus Total Salary Record\n",
    "for a in cmp_name:\n",
    "    c_namepluss_rec = [] \n",
    "    c_namepluss_rec = a.text.splitlines()\n",
    "    c_name.append(c_namepluss_rec[0])\n",
    "    s_rec.append(c_namepluss_rec[1]) \n",
    "e_req = [] \n",
    "exp_req = driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")   ## experience required\n",
    "for b in exp_req:\n",
    "    temp = [] \n",
    "    temp = b.text.splitlines()\n",
    "    e_req.append(temp[2])\n",
    "min_sal =[]\n",
    "m_sal1 = driver.find_elements_by_xpath(\"//div[@class='value body-medium'][1]\") ## minimum salary\n",
    "for c in m_sal1:\n",
    "    min_sal.append(c.text)\n",
    "max_sal = []\n",
    "m_sal2 = driver.find_elements_by_xpath(\"//div[@class='value body-medium'][2]\") ## maximum salary\n",
    "for d in m_sal2:\n",
    "    max_sal.append(d.text)\n",
    "avg_sal = []\n",
    "a_sal = driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")  ## average salary\n",
    "for e in a_sal:\n",
    "    avg_sal.append(e.text)\n",
    "\n",
    "## data frame\n",
    "ambi_df = pd.DataFrame({'Company Name':c_name,'Tot.Sal.Rec.':s_rec,'Avg.Sal.':avg_sal,'Min.Sal.':min_sal,'Max.Sal':max_sal,'Exp.Req.':e_req})\n",
    "print(ambi_df)\n",
    "\n",
    "driver.close()   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
